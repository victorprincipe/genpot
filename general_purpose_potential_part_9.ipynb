{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6338a405",
   "metadata": {},
   "source": [
    "# Creating a General Purpose Potential for Molecular Crystals - Part 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff43510b",
   "metadata": {},
   "source": [
    "This notebook is used to create a general purpose GAP potential for molecular crystals. The potential is built on PBE-D2 data from short PIMD simulations of 2238 different molecular crystals. Please note that it has a high (~150 GB) memory requirement to run fully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2df57e",
   "metadata": {},
   "source": [
    "In this part of the notebook: \n",
    "- Create a direct model using the exact same parameters as were used for the imrpvoed delta model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeab8a3",
   "metadata": {},
   "source": [
    "### Import modules, functions, and necessary raw data from parts 1, 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a9b1ef1",
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#Import modules\n",
    "from matplotlib import pylab as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "random_state = RandomState(0)\n",
    "from sklearn import linear_model\n",
    "import skcosmo.feature_selection\n",
    "#from skcosmo.feature_selection import FPS\n",
    "from skcosmo.sample_selection import PCovCUR, FPS\n",
    "from skcosmo.preprocessing import StandardFlexibleScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize, callbacks, dump, load\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "from skopt.plots import plot_convergence, plot_objective\n",
    "\n",
    "import ase\n",
    "from ase.io import read, write\n",
    "from ase.build import make_supercell\n",
    "from ase.visualize import view\n",
    "import numpy as np\n",
    "# If installed -- not essential, though\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except ImportError:\n",
    "    tqdm = (lambda i, **kwargs: i)\n",
    "\n",
    "from time import time, sleep\n",
    "\n",
    "from rascal.models import KRR\n",
    "from rascal.utils import dump_obj, load_obj\n",
    "\n",
    "from rascal.models import Kernel, train_gap_model, compute_KNM\n",
    "from rascal.representations import SphericalInvariants\n",
    "from rascal.neighbourlist.structure_manager import mask_center_atoms_by_species\n",
    "from rascal.representations.spherical_invariants import get_power_spectrum_index_mapping\n",
    "from rascal.utils import from_dict, to_dict, CURFilter, FPSFilter, dump_obj, load_obj\n",
    "from rascal.utils import get_score, get_optimal_radial_basis_hypers\n",
    "from rascal.utils.io import load_json, dump_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e3877a",
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "#Define functions\n",
    "def do_fps(x, d=0):\n",
    "    \"\"\"\n",
    "    Function for performing farthest-point-sampling for a given feature matrix.\n",
    "    d gives the number of farthest-point-sampled feature vectors that will be outputted. \n",
    "    If d==0, the entire set will be FPS-sorted.\n",
    "    Returns the FPS-sorted IDs, as well as the FPS distances.\n",
    "    \"\"\"\n",
    "    if d == 0 : d = len(x)\n",
    "    n = len(x)\n",
    "    iy = np.zeros(d, int)\n",
    "    # faster evaluation of Euclidean distance\n",
    "    n2 = np.sum(x**2,axis=1)\n",
    "    iy[0] = 0\n",
    "    dl = n2 + n2[iy[0]] - 2* np.dot(x, x[iy[0]])\n",
    "    dss = []\n",
    "    for i in range(1,d):\n",
    "        iy[i] = np.argmax(dl)\n",
    "        nd = n2 + n2[iy[i]] - 2*np.dot(x,x[iy[i]])\n",
    "        dl = np.minimum(dl, nd)\n",
    "        dss.append(max(dl))\n",
    "    return iy,dss\n",
    "\n",
    "def get_forces(frames, force_array='PBE-D2_forces'):\n",
    "    frc = np.zeros((np.sum([len(frm) for frm in frames]),3))\n",
    "    iat = 0\n",
    "    for ifrm,frm in enumerate(frames):\n",
    "        frc[iat:iat+len(frm)] = frm.get_array(force_array) \n",
    "        iat += len(frm)\n",
    "    return frc\n",
    "\n",
    "def get_features(atoms_objects, batch_size=1000, progress_bar=True):\n",
    "    '''Get average feature vectors for each structure in a list of atoms objects. \n",
    "        This requires soap to be set.\n",
    "    '''\n",
    "    struct_feat=[] #create empty feature vector of n_structures x n_features\n",
    "    got_frame = False\n",
    "    for frm in atoms_objects:\n",
    "        if got_frame == False: \n",
    "            if all(sp in frm.get_atomic_numbers() for sp in [1,6,7,8]) == True:\n",
    "                all_species = frm\n",
    "                got_frame = True\n",
    "    for i in tqdm(range(int(len(atoms_objects)/batch_size+0.9999)), disable = not progress_bar): #Get feature vectors in batches of 1000\n",
    "        for frm in atoms_objects[i*batch_size:(i+1)*batch_size]:\n",
    "            frm.wrap(eps=1e-13) #wrap atoms in unit cell\n",
    "        frames=[all_species.copy()] #add initial frame with all species\n",
    "        frames.extend(atoms_objects[i*batch_size:(i+1)*batch_size]) #extend initial frame with frames of batch\n",
    "        manager = soap.transform(frames) #calculate soap features for all structures in batch\n",
    "        env_feat_batch = manager.get_features(soap)[len(all_species):] #get feature vectors for all structures in batch\n",
    "        # (having removed the initial frame)\n",
    "        atom_counter=0 #count atoms\n",
    "        for ifrm,frm in enumerate(atoms_objects[i*batch_size:(i+1)*batch_size]): #iterate over frames in batch\n",
    "            nat=len(frm) #count atoms in frame\n",
    "            struct_feat.append(np.mean(env_feat_batch[atom_counter:atom_counter+nat],axis=0)) #average vectors\n",
    "            # for atoms in the same frame. Done by averaging vectors between atom_counter and atom_counter + nat\n",
    "            atom_counter+=nat #add atoms to counter\n",
    "    struct_feat_array=np.asarray(struct_feat)\n",
    "    return struct_feat_array\n",
    "\n",
    "def get_features_parallel(atoms_objects, bsize=1000, n_cores = 4):\n",
    "    '''Get average feature vectors for each structure in a list of atoms objects. \n",
    "        Do this in parallel\n",
    "    '''\n",
    "    blocks = []\n",
    "    for iblk, blk in enumerate(range(0, len(atoms_objects), bsize)):\n",
    "        blocks.append(atoms_objects[iblk*bsize:(iblk+1)*bsize])\n",
    "    with parallel_backend(backend=\"loky\"):\n",
    "        results = Parallel(n_jobs=n_cores)(delayed(get_features)(frames, batch_size=10000, \n",
    "                                                                 progress_bar=False) for frames in blocks)\n",
    "\n",
    "    return np.concatenate(results)\n",
    "\n",
    "def predict_batched(frames, ml_model):\n",
    "    man_pred = soap.transform(frames)\n",
    "    return ml_model.predict(man_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "849fe9cf",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vprincip/code/miniconda3/envs/genshift/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Ridge from version 1.1.0rc1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Import raw data\n",
    "train_set = np.load('raw_data/CSD-10k_train_set.npy', allow_pickle=True)\n",
    "val_set = np.load('raw_data/CSD-10k_val_set.npy', allow_pickle=True)\n",
    "test_set = np.load('raw_data/CSD-10k_test_set.npy', allow_pickle=True)\n",
    "X_train = np.load('raw_data/X_train.npy') \n",
    "y_train = np.load('raw_data/y_train.npy')\n",
    "X_val = np.load('raw_data/X_val.npy') \n",
    "y_val = np.load('raw_data/y_val.npy')\n",
    "X_test = np.load('raw_data/X_test.npy') \n",
    "y_test = np.load('raw_data/y_test.npy')\n",
    "X_train_fps = np.load('raw_data/X_train_fps.npy')\n",
    "y_train_fps = np.load('raw_data/y_train_fps.npy')\n",
    "fps_ids = np.load('raw_data/CSD-10k_train_set_FPS_ids.npy')\n",
    "fps_dist = np.load('raw_data/CSD-10k_train_set_FPS_dist.npy')\n",
    "with open('raw_data/mlr.pkl', 'rb') as mlr_file:\n",
    "    mlr = pickle.load(mlr_file)\n",
    "initial_train_set = np.load('raw_data/initial_train_set_4pc.npy', allow_pickle=True)\n",
    "train_set_FPS = np.load('model_data/train_set_FPS.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7890c8",
   "metadata": {},
   "source": [
    "### Compute necessary data and define SOAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6061b01d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Compute training, validation and testing data\n",
    "#Get training data for the FPS-sorted training set\n",
    "ytF = []\n",
    "for ifrm, frm in enumerate(train_set_FPS):\n",
    "    ytF.append(frm.info['energy'])\n",
    "ytrain_FPS = np.array(ytF)\n",
    "\n",
    "#Get true energies and forces for validation set\n",
    "yvt = []\n",
    "fvt = []\n",
    "\n",
    "for frm in val_set:\n",
    "    yvt.append(frm.info['energy'])\n",
    "    fvt.append(frm.get_array('forces'))\n",
    "\n",
    "yval_true = np.array(yvt)\n",
    "fval_true = np.concatenate(fvt)\n",
    "\n",
    "#Get true energies and forces for test set\n",
    "ytt = []\n",
    "ftt = []\n",
    "\n",
    "for frm in test_set:\n",
    "    ytt.append(frm.info['energy'])\n",
    "    ftt.append(frm.get_array('forces'))\n",
    "\n",
    "ytest_true = np.array(ytt)\n",
    "ftest_true = np.concatenate(ftt)\n",
    "\n",
    "#get dressed atom energies for reduced training set\n",
    "y_dressed = {}\n",
    "for i,j in enumerate([1,6,7,8]):\n",
    "    y_dressed[j] = mlr.coef_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc767762",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "zeta=3\n",
    "hypers = dict(soap_type=\"PowerSpectrum\",\n",
    "              interaction_cutoff=6, #cutoff distance in angstroms\n",
    "              max_radial=9, #no. of radial basis functions\n",
    "              max_angular=6, #no. of angular basis functions\n",
    "              gaussian_sigma_constant=0.4, #sigma width (i.e. amount of 'smearing')\n",
    "              gaussian_sigma_type=\"Constant\",\n",
    "              cutoff_function_type=\"RadialScaling\",\n",
    "              cutoff_smooth_width=0.5,\n",
    "              cutoff_function_parameters=\n",
    "                    dict(\n",
    "                            rate=1,\n",
    "                            scale=2,\n",
    "                            exponent=4\n",
    "                        ),\n",
    "              radial_basis=\"GTO\",\n",
    "              normalize=True,\n",
    "              optimization=\n",
    "                    dict(\n",
    "                            Spline=dict(\n",
    "                               accuracy=1.0e-05\n",
    "                            )\n",
    "                        ),\n",
    "              compute_gradients=False \n",
    "              )\n",
    "soap = SphericalInvariants(**hypers) #redefine soap with new parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecce45b",
   "metadata": {},
   "source": [
    "## Reload database with DFTB+ results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee6f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Re-)Open dataset\n",
    "with open('delta_data/CSD-10k_combined_w_kpts_11_pc_w_DFTB.pickle', 'rb') as f:\n",
    "    db = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ebdf87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add energy and force deltas to frame\n",
    "for name in db.keys():\n",
    "    for frm in db[name]:\n",
    "        frm.info['Delta_energy'] = frm.info['PBE-D2_energy'] - frm.info['DFTB_energy']\n",
    "        frm.arrays['Delta_forces'] = frm.arrays['PBE-D2_forces'] - frm.arrays['DFTB_forces']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f70609",
   "metadata": {},
   "source": [
    "## Create training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c22cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training and val sets\n",
    "all_frames = []\n",
    "for name in db.keys():\n",
    "    for frm in db[name]:\n",
    "        all_frames.append(frm)\n",
    "\n",
    "ids = np.arange(len(all_frames))\n",
    "np.random.seed(10)\n",
    "np.random.shuffle(ids)\n",
    "\n",
    "train_frames = [all_frames[i] for i in ids[1000:]]\n",
    "val_frames = [all_frames[i] for i in ids[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc4b25c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create composition (X), energy deltas (y) and force deltas (f) arrays\n",
    "X_all = np.zeros((len(all_frames), 4), dtype=int) ; y_all = np.zeros(len(all_frames), dtype=float)\n",
    "f_all = np.zeros((np.sum([len(frm) for frm in all_frames]),3), dtype=float)\n",
    "\n",
    "counter = 0\n",
    "for ifrm, frm in enumerate(all_frames):\n",
    "    symbols = frm.get_atomic_numbers()\n",
    "    X_all[ifrm] = [len(np.where(symbols == sp)[0]) for sp in [1,6,7,8]]\n",
    "    y_all[ifrm] = frm.info['PBE-D2_energy']\n",
    "    f_all[counter:counter+len(frm)] = frm.arrays['PBE-D2_forces']\n",
    "    counter += len(frm)\n",
    "    \n",
    "X_train = np.zeros((len(train_frames), 4), dtype=int) ; y_train = np.zeros(len(train_frames), dtype=float)\n",
    "f_train = np.zeros((np.sum([len(frm) for frm in train_frames]),3), dtype=float)\n",
    "\n",
    "counter = 0\n",
    "for ifrm, frm in enumerate(train_frames):\n",
    "    symbols = frm.get_atomic_numbers()\n",
    "    X_train[ifrm] = [len(np.where(symbols == sp)[0]) for sp in [1,6,7,8]]\n",
    "    y_train[ifrm] = frm.info['PBE-D2_energy']\n",
    "    f_train[counter:counter+len(frm)] = frm.arrays['PBE-D2_forces']\n",
    "    counter += len(frm)\n",
    "\n",
    "X_val = np.zeros((len(val_frames), 4), dtype=int) ; y_val = np.zeros(len(val_frames), dtype=float)\n",
    "f_val = np.zeros((np.sum([len(frm) for frm in val_frames]),3), dtype=float)\n",
    "\n",
    "counter = 0\n",
    "for ifrm, frm in enumerate(val_frames):\n",
    "    symbols = frm.get_atomic_numbers()\n",
    "    X_val[ifrm] = [len(np.where(symbols == sp)[0]) for sp in [1,6,7,8]]\n",
    "    y_val[ifrm] = frm.info['PBE-D2_energy']\n",
    "    f_val[counter:counter+len(frm)] = frm.arrays['PBE-D2_forces']\n",
    "    counter += len(frm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d23599ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-atom energy for species H : -16.468153332304176 eV\n",
      "Per-atom energy for species C : -154.7200109174649 eV\n",
      "Per-atom energy for species N : -383.3442075581302 eV\n",
      "Per-atom energy for species O : -566.2270341988528 eV\n"
     ]
    }
   ],
   "source": [
    "#Create baselined per-atom energy model\n",
    "mlr = Ridge(fit_intercept=False, alpha=1e-4)\n",
    "mlr.fit(X_all, y_all)\n",
    "for spec, coef in zip(['H', 'C', 'N', 'O'], mlr.coef_):\n",
    "    print(f\"Per-atom energy for species {spec} : {coef} eV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "687fa29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dressed atom energies for reduced training set\n",
    "y_dressed = {}\n",
    "for i,j in enumerate([1,6,7,8]):\n",
    "    y_dressed[j] = mlr.coef_[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334fbe69",
   "metadata": {},
   "source": [
    "## Get PCovFPS Sample and Feature IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b7b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload PCovFPS-sorted sample IDs\n",
    "pcf_ids = np.load('delta_data/pcovfps_selected_idx.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34a813b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload PCovFPS-sorted sample IDs\n",
    "pcf_feat_ids = np.load('delta_data/pcovfps_features_selected_idx.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65633e0a",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d627986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define soap hyperparameters\n",
    "zeta=3\n",
    "hypers = dict(soap_type=\"PowerSpectrum\",\n",
    "              interaction_cutoff=6, #cutoff distance in angstroms\n",
    "              max_radial=9, #no. of radial basis functions\n",
    "              max_angular=6, #no. of angular basis functions\n",
    "              gaussian_sigma_constant=0.4, #sigma width (i.e. amount of 'smearing')\n",
    "              gaussian_sigma_type=\"Constant\",\n",
    "              cutoff_function_type=\"RadialScaling\",\n",
    "              cutoff_smooth_width=0.5,\n",
    "              cutoff_function_parameters=\n",
    "                    dict(\n",
    "                            rate=1,\n",
    "                            scale=2,\n",
    "                            exponent=4\n",
    "                        ),\n",
    "              radial_basis=\"GTO\",\n",
    "              normalize=True,\n",
    "              optimization=\n",
    "                    dict(\n",
    "                            Spline=dict(\n",
    "                               accuracy=1.0e-05\n",
    "                            )\n",
    "                        ),\n",
    "              compute_gradients=False #don't care about forces right now\n",
    "              )\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71df03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure out which indices are mapped to which features\n",
    "sp_pairs = soap.get_keys([1, 6, 7, 8])\n",
    "mapping = get_power_spectrum_index_mapping(\n",
    "    sp_pairs, n_max=hypers[\"max_radial\"], l_max=hypers[\"max_angular\"]+1 \n",
    ") # +1 in lmax needed because of some Librascal bug (Rose said)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53a41024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tell soap to only use indices from PCovFPS sorting\n",
    "n_feats = 2500 #use this number of features (determined from the feature optimisation)\n",
    "a = [mapping[i]['a'] for i in pcf_feat_ids[:n_feats]]\n",
    "b = [mapping[i]['b'] for i in pcf_feat_ids[:n_feats]]\n",
    "n1 = [mapping[i]['n1'] for i in pcf_feat_ids[:n_feats]]\n",
    "n2 = [mapping[i]['n2'] for i in pcf_feat_ids[:n_feats]]\n",
    "l = [mapping[i]['l'] for i in pcf_feat_ids[:n_feats]]\n",
    "\n",
    "hypers['coefficient_subselection'] = {\"a\": a, \"b\": b, \"n1\": n1, \"n2\":n2, \"l\":l}\n",
    "soap = SphericalInvariants(**hypers)\n",
    "#soap = SphericalInvariants(**hypers, coefficient_subselection={\"a\": a, \"b\": b, \"n1\": n1, \"n2\":n2, \"l\":l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37a149bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create PCov-FPS sorted training database\n",
    "n_train = 15000 #choose (optimal) number of training structures\n",
    "pcf_train_frames = []; pcf_X_train=np.zeros((n_train, 4)); pcf_y_train=np.zeros(n_train); \n",
    "\n",
    "for ii, i in enumerate(pcf_ids[:n_train]):\n",
    "    frm = train_frames[i]\n",
    "    pcf_train_frames.append(frm)\n",
    "    symbols = frm.get_atomic_numbers()\n",
    "    pcf_X_train[ii] = [len(np.where(symbols == sp)[0]) for sp in [1,6,7,8]]\n",
    "    pcf_y_train[ii] = frm.info['PBE-D2_energy']\n",
    "\n",
    "pcf_yred_train = pcf_y_train/np.sum(pcf_X_train,axis=1)-mlr.predict(pcf_X_train)/np.sum(pcf_X_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "110d0cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing feature matrices...\n",
      "Time taken:  441.4656546115875 s\n"
     ]
    }
   ],
   "source": [
    "# Compute feature matrices\n",
    "print(\"Computing feature matrices...\")\n",
    "start=time()\n",
    "manager_train = soap.transform(pcf_train_frames) #calculating features\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b17c4d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsifying training set...\n",
      "The number of pseudo points selected by central atom species is: {1: 2000, 6: 2000, 7: 2000, 8: 2000}\n",
      "Selecting species: 1\n",
      "Selecting species: 6\n",
      "Selecting species: 7\n",
      "Selecting species: 8\n",
      "Time taken:  5460.437185287476 s\n"
     ]
    }
   ],
   "source": [
    "# Use an FPS filter to obtain desired number of sparse points per species\n",
    "nh = 2000\n",
    "nc = 2000\n",
    "nn = 2000\n",
    "no = 2000\n",
    "nsparse    = {1: nh, 6: nc, 7: nn, 8: no} #Select number of sparse environemnts per species\n",
    "compressor = FPSFilter(soap,nsparse,act_on='sample per species') #Filter to sparsify full feature matrix\n",
    "print(\"Sparsifying training set...\")\n",
    "start=time()\n",
    "X_sparse = compressor.select_and_filter(manager_train) #Apply filter to training set\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe9abe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_obj('raw_data/X_sparse_15k_d_params.json', X_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00f11695",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse = load_obj('delta_data/X_sparse_15k_d_params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3888dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define kernel and redefine hypers \n",
    "hypers[\"compute_gradients\"] = True #we want to compute gradients (forces) for the kernel\n",
    "soap = SphericalInvariants(**hypers)\n",
    "kernel = Kernel(soap, name='GAP', zeta=zeta, target_type='Structure', kernel_type='Sparse') #Define Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6d6be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512e815ad3414bbda22ef6b81cd796e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Compute KNM:   0%|          | 0/15000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Compute kernel\n",
    "start=time()\n",
    "Knm = compute_KNM(tqdm(pcf_train_frames, desc=\"Compute KNM\", leave=False), X_sparse, kernel, soap)\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c0457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save kernel\n",
    "np.save('raw_data/Knm_kernel_15k_d_params', Knm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9511a45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Knm...\n",
      "Knm loading time: 1906.5201878547668 s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "print(\"Loading Knm...\")\n",
    "Knm = np.load('raw_data/Knm_kernel_15k_d_params.npy')\n",
    "print(\"Knm loading time:\", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccfdeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train GAP model\n",
    "print(\"Training GAP model...\")\n",
    "start = time()\n",
    "full_model = train_gap_model(kernel, pcf_train_frames, Knm, X_sparse, pcf_y_train, y_dressed, \n",
    "                             grad_train=-get_forces(pcf_train_frames), lambdas=[0.046416,1.160397], \n",
    "                             jitter=1e-9, solver = 'RKHS')\n",
    "print(\"Time taken:\", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10583f11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Save model\n",
    "dump_obj('delta_data/GAP_model_15k_0.05_1.json', full_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": "9",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
