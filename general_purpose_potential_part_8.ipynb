{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6338a405",
   "metadata": {},
   "source": [
    "# Creating a General Purpose Potential for Molecular Crystals - Part 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff43510b",
   "metadata": {},
   "source": [
    "This notebook is used to create a general purpose GAP potential for molecular crystals. The potential is built on PBE-D3 data from short PIMD simulations of 2238 different molecular crystals. Please note that it has a high (~150 GB) memory requirement to run fully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2df57e",
   "metadata": {},
   "source": [
    "In this part of the notebook: \n",
    "- Move to Rascaline \n",
    "- Determine speed increases using Rascaline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeab8a3",
   "metadata": {},
   "source": [
    "### Import modules, functions, and necessary raw data from parts 1, 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a9b1ef1",
   "metadata": {
    "code_folding": [],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#Import modules\n",
    "from matplotlib import pylab as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "random_state = RandomState(0)\n",
    "from sklearn import linear_model\n",
    "import skcosmo.feature_selection\n",
    "#from skcosmo.feature_selection import FPS\n",
    "from skcosmo.sample_selection import PCovCUR, FPS\n",
    "from skcosmo.preprocessing import StandardFlexibleScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize, callbacks, dump, load\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "from skopt.plots import plot_convergence, plot_objective\n",
    "\n",
    "import ase\n",
    "from ase.io import read, write\n",
    "from ase.build import make_supercell\n",
    "from ase.visualize import view\n",
    "import numpy as np\n",
    "# If installed -- not essential, though\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except ImportError:\n",
    "    tqdm = (lambda i, **kwargs: i)\n",
    "\n",
    "from time import time, sleep\n",
    "\n",
    "from rascal.models import KRR\n",
    "from rascal.utils import dump_obj, load_obj\n",
    "\n",
    "from rascal.models import Kernel, train_gap_model, compute_KNM\n",
    "from rascal.representations import SphericalInvariants\n",
    "from rascal.neighbourlist.structure_manager import mask_center_atoms_by_species\n",
    "from rascal.utils import from_dict, to_dict, CURFilter, FPSFilter, dump_obj, load_obj\n",
    "from rascal.utils import get_score, get_optimal_radial_basis_hypers\n",
    "from rascal.utils.io import load_json, dump_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e3877a",
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "#Define functions\n",
    "def do_fps(x, d=0):\n",
    "    \"\"\"\n",
    "    Function for performing farthest-point-sampling for a given feature matrix.\n",
    "    d gives the number of farthest-point-sampled feature vectors that will be outputted. \n",
    "    If d==0, the entire set will be FPS-sorted.\n",
    "    Returns the FPS-sorted IDs, as well as the FPS distances.\n",
    "    \"\"\"\n",
    "    if d == 0 : d = len(x)\n",
    "    n = len(x)\n",
    "    iy = np.zeros(d, int)\n",
    "    # faster evaluation of Euclidean distance\n",
    "    n2 = np.sum(x**2,axis=1)\n",
    "    iy[0] = 0\n",
    "    dl = n2 + n2[iy[0]] - 2* np.dot(x, x[iy[0]])\n",
    "    dss = []\n",
    "    for i in range(1,d):\n",
    "        iy[i] = np.argmax(dl)\n",
    "        nd = n2 + n2[iy[i]] - 2*np.dot(x,x[iy[i]])\n",
    "        dl = np.minimum(dl, nd)\n",
    "        dss.append(max(dl))\n",
    "    return iy,dss\n",
    "\n",
    "def get_forces(frames):\n",
    "    frc = np.zeros((np.sum([len(frm) for frm in frames]),3))\n",
    "    iat = 0\n",
    "    for ifrm,frm in enumerate(frames):\n",
    "        frc[iat:iat+len(frm)] = frm.get_array('forces') \n",
    "        iat += len(frm)\n",
    "    return frc\n",
    "\n",
    "def get_features(atoms_objects, batch_size=1000, progress_bar=True):\n",
    "    '''Get average feature vectors for each structure in a list of atoms objects. \n",
    "        This requires soap to be set.\n",
    "    '''\n",
    "    struct_feat=[] #create empty feature vector of n_structures x n_features\n",
    "    got_frame = False\n",
    "    for frm in atoms_objects:\n",
    "        if got_frame == False: \n",
    "            if all(sp in frm.get_atomic_numbers() for sp in [1,6,7,8]) == True:\n",
    "                all_species = frm\n",
    "                got_frame = True\n",
    "    for i in tqdm(range(int(len(atoms_objects)/batch_size+0.9999)), disable = not progress_bar): #Get feature vectors in batches of 1000\n",
    "        for frm in atoms_objects[i*batch_size:(i+1)*batch_size]:\n",
    "            frm.wrap(eps=1e-13) #wrap atoms in unit cell\n",
    "        frames=[all_species.copy()] #add initial frame with all species\n",
    "        frames.extend(atoms_objects[i*batch_size:(i+1)*batch_size]) #extend initial frame with frames of batch\n",
    "        manager = soap.transform(frames) #calculate soap features for all structures in batch\n",
    "        env_feat_batch = manager.get_features(soap)[len(all_species):] #get feature vectors for all structures in batch\n",
    "        # (having removed the initial frame)\n",
    "        atom_counter=0 #count atoms\n",
    "        for ifrm,frm in enumerate(atoms_objects[i*batch_size:(i+1)*batch_size]): #iterate over frames in batch\n",
    "            nat=len(frm) #count atoms in frame\n",
    "            struct_feat.append(np.mean(env_feat_batch[atom_counter:atom_counter+nat],axis=0)) #average vectors\n",
    "            # for atoms in the same frame. Done by averaging vectors between atom_counter and atom_counter + nat\n",
    "            atom_counter+=nat #add atoms to counter\n",
    "    struct_feat_array=np.asarray(struct_feat)\n",
    "    return struct_feat_array\n",
    "\n",
    "def get_features_parallel(atoms_objects, bsize=1000, n_cores = 4):\n",
    "    '''Get average feature vectors for each structure in a list of atoms objects. \n",
    "        Do this in parallel\n",
    "    '''\n",
    "    blocks = []\n",
    "    for iblk, blk in enumerate(range(0, len(atoms_objects), bsize)):\n",
    "        blocks.append(atoms_objects[iblk*bsize:(iblk+1)*bsize])\n",
    "    with parallel_backend(backend=\"loky\"):\n",
    "        results = Parallel(n_jobs=n_cores)(delayed(get_features)(frames, batch_size=10000, \n",
    "                                                                 progress_bar=False) for frames in blocks)\n",
    "\n",
    "    return np.concatenate(results)\n",
    "\n",
    "def predict_batched(frames, ml_model):\n",
    "    man_pred = soap.transform(frames)\n",
    "    return ml_model.predict(man_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "849fe9cf",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vprincip/code/miniconda3/envs/genshift/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Ridge from version 1.1.0rc1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Import raw data\n",
    "train_set = np.load('raw_data/CSD-10k_train_set.npy', allow_pickle=True)\n",
    "val_set = np.load('raw_data/CSD-10k_val_set.npy', allow_pickle=True)\n",
    "test_set = np.load('raw_data/CSD-10k_test_set.npy', allow_pickle=True)\n",
    "X_train = np.load('raw_data/X_train.npy') \n",
    "y_train = np.load('raw_data/y_train.npy')\n",
    "X_val = np.load('raw_data/X_val.npy') \n",
    "y_val = np.load('raw_data/y_val.npy')\n",
    "X_test = np.load('raw_data/X_test.npy') \n",
    "y_test = np.load('raw_data/y_test.npy')\n",
    "X_train_fps = np.load('raw_data/X_train_fps.npy')\n",
    "y_train_fps = np.load('raw_data/y_train_fps.npy')\n",
    "fps_ids = np.load('raw_data/CSD-10k_train_set_FPS_ids.npy')\n",
    "fps_dist = np.load('raw_data/CSD-10k_train_set_FPS_dist.npy')\n",
    "with open('raw_data/mlr.pkl', 'rb') as mlr_file:\n",
    "    mlr = pickle.load(mlr_file)\n",
    "initial_train_set = np.load('raw_data/initial_train_set_4pc.npy', allow_pickle=True)\n",
    "train_set_FPS = np.load('model_data/train_set_FPS.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7890c8",
   "metadata": {},
   "source": [
    "### Compute necessary data and define SOAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6061b01d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Compute training, validation and testing data\n",
    "#Get training data for the FPS-sorted training set\n",
    "ytF = []\n",
    "for ifrm, frm in enumerate(train_set_FPS):\n",
    "    ytF.append(frm.info['energy'])\n",
    "ytrain_FPS = np.array(ytF)\n",
    "\n",
    "#Get true energies and forces for validation set\n",
    "yvt = []\n",
    "fvt = []\n",
    "\n",
    "for frm in val_set:\n",
    "    yvt.append(frm.info['energy'])\n",
    "    fvt.append(frm.get_array('forces'))\n",
    "\n",
    "yval_true = np.array(yvt)\n",
    "fval_true = np.concatenate(fvt)\n",
    "\n",
    "#Get true energies and forces for test set\n",
    "ytt = []\n",
    "ftt = []\n",
    "\n",
    "for frm in test_set:\n",
    "    ytt.append(frm.info['energy'])\n",
    "    ftt.append(frm.get_array('forces'))\n",
    "\n",
    "ytest_true = np.array(ytt)\n",
    "ftest_true = np.concatenate(ftt)\n",
    "\n",
    "#get dressed atom energies for reduced training set\n",
    "y_dressed = {}\n",
    "for i,j in enumerate([1,6,7,8]):\n",
    "    y_dressed[j] = mlr.coef_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc767762",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "zeta=3\n",
    "hypers = dict(soap_type=\"PowerSpectrum\",\n",
    "              interaction_cutoff=6, #cutoff distance in angstroms\n",
    "              max_radial=9, #no. of radial basis functions\n",
    "              max_angular=6, #no. of angular basis functions\n",
    "              gaussian_sigma_constant=0.4, #sigma width (i.e. amount of 'smearing')\n",
    "              gaussian_sigma_type=\"Constant\",\n",
    "              cutoff_function_type=\"RadialScaling\",\n",
    "              cutoff_smooth_width=0.5,\n",
    "              cutoff_function_parameters=\n",
    "                    dict(\n",
    "                            rate=1,\n",
    "                            scale=2,\n",
    "                            exponent=4\n",
    "                        ),\n",
    "              radial_basis=\"GTO\",\n",
    "              normalize=True,\n",
    "              optimization=\n",
    "                    dict(\n",
    "                            Spline=dict(\n",
    "                               accuracy=1.0e-05\n",
    "                            )\n",
    "                        ),\n",
    "              compute_gradients=False \n",
    "              )\n",
    "soap = SphericalInvariants(**hypers) #redefine soap with new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826979b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d27004f",
   "metadata": {},
   "source": [
    "## Start using Rascaline\n",
    "Let's start using Rascaline and compare its feature computation time with the older Rascal.\n",
    "\n",
    "We will compare computation time with Rascal for gradients too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520e7f59",
   "metadata": {},
   "source": [
    "### Compare speed without gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cdc27dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Rascaline-style and SOAP hypers\n",
    "zeta=3\n",
    "hypers = dict(soap_type='PowerSpectrum',\n",
    "              interaction_cutoff=6, #cutoff distance in angstroms\n",
    "              max_radial=9, #no. of radial basis functions\n",
    "              max_angular=6, #no. of angular basis functions\n",
    "              gaussian_sigma_constant=0.4, #sigma width (i.e. amount of 'smearing')\n",
    "              gaussian_sigma_type=\"Constant\",\n",
    "              cutoff_function_type=\"RadialScaling\",\n",
    "              cutoff_smooth_width=0.5,\n",
    "              cutoff_function_parameters=\n",
    "                    dict(\n",
    "                            rate=1,\n",
    "                            scale=2,\n",
    "                            exponent=4\n",
    "                        ),\n",
    "              radial_basis=\"GTO\",\n",
    "              normalize=False,\n",
    "              optimization=\n",
    "                    dict(\n",
    "                            Spline=dict(\n",
    "                               accuracy=1.0e-05\n",
    "                            )\n",
    "                        ),\n",
    "              compute_gradients=False \n",
    "              )\n",
    "soap = SphericalInvariants(**hypers) #redefine soap with new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8cf6246a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1.7594s\n"
     ]
    }
   ],
   "source": [
    "# Compute features using rascal\n",
    "start=time()\n",
    "for frm in tqdm(train_set[:100]):\n",
    "    soap.transform(frm)\n",
    "print(f\"Time taken: {np.round(time()-start, 4)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1eb5de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rascaline import SoapPowerSpectrum\n",
    "\n",
    "HYPER_PARAMETERS = {\n",
    "    \"cutoff\": 6,\n",
    "    \"max_radial\": 9,\n",
    "    \"max_angular\": 6,\n",
    "    \"atomic_gaussian_width\": 0.4,\n",
    "    \"center_atom_weight\": 1.0,\n",
    "    \"radial_basis\": {\n",
    "        \"Gto\": {\"spline_accuracy\": 1e-5},\n",
    "    },\n",
    "    \"cutoff_function\": {\n",
    "        \"ShiftedCosine\": {\"width\": 0.5},\n",
    "        \n",
    "    },\n",
    "    \"radial_scaling\":{\n",
    "        \"Willatt2018\": {\"exponent\": 4, \"rate\": 1, \"scale\": 2},\n",
    "    },\n",
    "}\n",
    "\n",
    "calculator = SoapPowerSpectrum(**HYPER_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ea245dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26247c3d246347d8892898e25a731944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 5.4109s\n"
     ]
    }
   ],
   "source": [
    "# Compute features using rascaline\n",
    "start=time()\n",
    "for frm in tqdm(train_set[:100]):\n",
    "    calculator.compute(frm)\n",
    "print(f\"Time taken: {np.round(time()-start, 4)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b49056",
   "metadata": {},
   "source": [
    "Seems like Rascaline is about a third the speed of Rascal when not computing gradients. Let's see how they compare when computing gradients too..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5112d48b",
   "metadata": {},
   "source": [
    "### Compare speed with gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed794cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers[\"compute_gradients\"] = True\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da6c5d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee611afa1d3e4971a56400e1c80b7ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 7.2975s\n"
     ]
    }
   ],
   "source": [
    "# Compute features using rascal\n",
    "start=time()\n",
    "for frm in tqdm(train_set[:10]):\n",
    "    soap.transform(frm)\n",
    "print(f\"Time taken: {np.round(time()-start, 4)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "97f89d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29c000fefe849f4a7633d8479953b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 3.7109s\n"
     ]
    }
   ],
   "source": [
    "# Compute features using rascaline\n",
    "start=time()\n",
    "for frm in tqdm(train_set[:10]):\n",
    "    calculator.compute(frm, gradients=[\"positions\"])\n",
    "print(f\"Time taken: {np.round(time()-start, 4)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213211d2",
   "metadata": {},
   "source": [
    "The true benefit of using rascaline becomes clear when computing gradients, which is about twice as fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "db3f3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for normalizing a TensorMap\n",
    "def normalize(descriptor):\n",
    "    blocks = []\n",
    "    for _, block in descriptor:\n",
    "        # only deal with invariants for now\n",
    "        assert len(block.components) == 0\n",
    "        assert len(block.values.shape) == 2\n",
    "\n",
    "        norm = ops.norm(block.values, axis=1)\n",
    "        normalized_values = block.values / norm[:, None]\n",
    "\n",
    "        new_block = TensorBlock(\n",
    "            values=normalized_values,\n",
    "            samples=block.samples,\n",
    "            components=[],\n",
    "            properties=block.properties,\n",
    "        )\n",
    "\n",
    "        if block.has_gradient(\"positions\"):\n",
    "            gradient = block.gradient(\"positions\")\n",
    "\n",
    "            gradient_data = gradient.data / norm[gradient.samples[\"sample\"], None, None]\n",
    "\n",
    "            # gradient of x_i = X_i / N_i is given by\n",
    "            # 1 / N_i \\grad X_i - x_i [x_i @ 1 / N_i \\grad X_i]\n",
    "            for sample_i, (sample, _, _) in enumerate(gradient.samples):\n",
    "                dot = gradient_data[sample_i] @ normalized_values[sample].T\n",
    "\n",
    "                gradient_data[sample_i, 0, :] -= dot[0] * normalized_values[sample, :]\n",
    "                gradient_data[sample_i, 1, :] -= dot[1] * normalized_values[sample, :]\n",
    "                gradient_data[sample_i, 2, :] -= dot[2] * normalized_values[sample, :]\n",
    "\n",
    "            new_block.add_gradient(\n",
    "                \"positions\", gradient_data, gradient.samples, gradient.components\n",
    "            )\n",
    "\n",
    "        blocks.append(new_block)\n",
    "\n",
    "    return TensorMap(descriptor.keys, blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412bdd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": "8",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
