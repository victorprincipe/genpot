{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6338a405",
   "metadata": {},
   "source": [
    "# Creating a General Purpose Potential for Molecular Crystals - Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff43510b",
   "metadata": {},
   "source": [
    "This notebook is used to create a general purpose GAP potential for molecular crystals. The potential is built on PBE-D3 data from short PIMD simulations of 2238 different molecular crystals. Please note that it has a high (~150 GB) memory requirement to run fully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2df57e",
   "metadata": {},
   "source": [
    "In this part of the notebook: \n",
    "- Tests..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeab8a3",
   "metadata": {},
   "source": [
    "### Import modules, functions, and necessary raw data from parts 1, 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a9b1ef1",
   "metadata": {
    "code_folding": [
     0
    ],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "#Import modules\n",
    "from matplotlib import pylab as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from numpy.random import RandomState\n",
    "random_state = RandomState(0)\n",
    "from sklearn import linear_model\n",
    "import skcosmo.feature_selection\n",
    "#from skcosmo.feature_selection import FPS\n",
    "from skcosmo.sample_selection import PCovCUR, FPS\n",
    "from skcosmo.preprocessing import StandardFlexibleScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize, callbacks, dump, load\n",
    "from skopt.callbacks import CheckpointSaver\n",
    "from skopt.plots import plot_convergence, plot_objective\n",
    "\n",
    "import ase\n",
    "from ase.io import read, write\n",
    "from ase.build import make_supercell\n",
    "from ase.visualize import view\n",
    "import numpy as np\n",
    "# If installed -- not essential, though\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except ImportError:\n",
    "    tqdm = (lambda i, **kwargs: i)\n",
    "\n",
    "from time import time, sleep\n",
    "\n",
    "from rascal.models import KRR\n",
    "from rascal.utils import dump_obj, load_obj\n",
    "\n",
    "from rascal.models import Kernel, train_gap_model, compute_KNM\n",
    "from rascal.representations import SphericalInvariants\n",
    "from rascal.neighbourlist.structure_manager import mask_center_atoms_by_species\n",
    "from rascal.utils import from_dict, to_dict, CURFilter, FPSFilter, dump_obj, load_obj\n",
    "from rascal.utils import get_score, get_optimal_radial_basis_hypers\n",
    "from rascal.utils.io import load_json, dump_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a03fb45",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Import SOAP Bayesian optimisation modules\n",
    "import sys  \n",
    "sys.path.insert(0, '../code/SOAP-bayes/')\n",
    "from helpers import get_features_in_parallel, get_optimal_radial_basis_hypers_parallel\n",
    "from feature_skcosmo import atom_groups_by_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e3877a",
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "#Define functions\n",
    "def do_fps(x, d=0):\n",
    "    \"\"\"\n",
    "    Function for performing farthest-point-sampling for a given feature matrix.\n",
    "    d gives the number of farthest-point-sampled feature vectors that will be outputted. \n",
    "    If d==0, the entire set will be FPS-sorted.\n",
    "    Returns the FPS-sorted IDs, as well as the FPS distances.\n",
    "    \"\"\"\n",
    "    if d == 0 : d = len(x)\n",
    "    n = len(x)\n",
    "    iy = np.zeros(d, int)\n",
    "    # faster evaluation of Euclidean distance\n",
    "    n2 = np.sum(x**2,axis=1)\n",
    "    iy[0] = 0\n",
    "    dl = n2 + n2[iy[0]] - 2* np.dot(x, x[iy[0]])\n",
    "    dss = []\n",
    "    for i in range(1,d):\n",
    "        iy[i] = np.argmax(dl)\n",
    "        nd = n2 + n2[iy[i]] - 2*np.dot(x,x[iy[i]])\n",
    "        dl = np.minimum(dl, nd)\n",
    "        dss.append(max(dl))\n",
    "    return iy,dss\n",
    "\n",
    "def get_forces(frames):\n",
    "    frc = np.zeros((np.sum([len(frm) for frm in frames]),3))\n",
    "    iat = 0\n",
    "    for ifrm,frm in enumerate(frames):\n",
    "        frc[iat:iat+len(frm)] = frm.get_array('forces') \n",
    "        iat += len(frm)\n",
    "    return frc\n",
    "\n",
    "def get_features(atoms_objects, batch_size=1000, progress_bar=True):\n",
    "    '''Get average feature vectors for each structure in a list of atoms objects. \n",
    "        This requires soap to be set.\n",
    "    '''\n",
    "    struct_feat=[] #create empty feature vector of n_structures x n_features\n",
    "    got_frame = False\n",
    "    for frm in atoms_objects:\n",
    "        if got_frame == False: \n",
    "            if all(sp in frm.get_atomic_numbers() for sp in [1,6,7,8]) == True:\n",
    "                all_species = frm\n",
    "                got_frame = True\n",
    "    for i in tqdm(range(int(len(atoms_objects)/batch_size+0.9999)), disable = not progress_bar): #Get feature vectors in batches of 1000\n",
    "        for frm in atoms_objects[i*batch_size:(i+1)*batch_size]:\n",
    "            frm.wrap(eps=1e-13) #wrap atoms in unit cell\n",
    "        frames=[all_species.copy()] #add initial frame with all species\n",
    "        frames.extend(atoms_objects[i*batch_size:(i+1)*batch_size]) #extend initial frame with frames of batch\n",
    "        manager = soap.transform(frames) #calculate soap features for all structures in batch\n",
    "        env_feat_batch = manager.get_features(soap)[len(all_species):] #get feature vectors for all structures in batch\n",
    "        # (having removed the initial frame)\n",
    "        atom_counter=0 #count atoms\n",
    "        for ifrm,frm in enumerate(atoms_objects[i*batch_size:(i+1)*batch_size]): #iterate over frames in batch\n",
    "            nat=len(frm) #count atoms in frame\n",
    "            struct_feat.append(np.mean(env_feat_batch[atom_counter:atom_counter+nat],axis=0)) #average vectors\n",
    "            # for atoms in the same frame. Done by averaging vectors between atom_counter and atom_counter + nat\n",
    "            atom_counter+=nat #add atoms to counter\n",
    "    struct_feat_array=np.asarray(struct_feat)\n",
    "    return struct_feat_array\n",
    "\n",
    "def get_features_parallel(atoms_objects, bsize=1000, n_cores = 4):\n",
    "    '''Get average feature vectors for each structure in a list of atoms objects. \n",
    "        Do this in parallel\n",
    "    '''\n",
    "    blocks = []\n",
    "    for iblk, blk in enumerate(range(0, len(atoms_objects), bsize)):\n",
    "        blocks.append(atoms_objects[iblk*bsize:(iblk+1)*bsize])\n",
    "    with parallel_backend(backend=\"loky\"):\n",
    "        results = Parallel(n_jobs=n_cores)(delayed(get_features)(frames, batch_size=10000, \n",
    "                                                                 progress_bar=False) for frames in blocks)\n",
    "\n",
    "    return np.concatenate(results)\n",
    "\n",
    "def predict_batched(frames, ml_model):\n",
    "    man_pred = soap.transform(frames)\n",
    "    return ml_model.predict(man_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849fe9cf",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vprincip/code/miniconda3/envs/genshift/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Ridge from version 1.1.0rc1 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Import raw data\n",
    "train_set = np.load('raw_data/CSD-10k_train_set.npy', allow_pickle=True)\n",
    "val_set = np.load('raw_data/CSD-10k_val_set.npy', allow_pickle=True)\n",
    "test_set = np.load('raw_data/CSD-10k_test_set.npy', allow_pickle=True)\n",
    "X_train = np.load('raw_data/X_train.npy') \n",
    "y_train = np.load('raw_data/y_train.npy')\n",
    "X_val = np.load('raw_data/X_val.npy') \n",
    "y_val = np.load('raw_data/y_val.npy')\n",
    "X_test = np.load('raw_data/X_test.npy') \n",
    "y_test = np.load('raw_data/y_test.npy')\n",
    "X_train_fps = np.load('raw_data/X_train_fps.npy')\n",
    "y_train_fps = np.load('raw_data/y_train_fps.npy')\n",
    "fps_ids = np.load('raw_data/CSD-10k_train_set_FPS_ids.npy')\n",
    "fps_dist = np.load('raw_data/CSD-10k_train_set_FPS_dist.npy')\n",
    "with open('raw_data/mlr.pkl', 'rb') as mlr_file:\n",
    "    mlr = pickle.load(mlr_file)\n",
    "initial_train_set = np.load('raw_data/initial_train_set_4pc.npy', allow_pickle=True)\n",
    "train_set_FPS = np.load('model_data/train_set_FPS.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7890c8",
   "metadata": {},
   "source": [
    "### Compute necessary data and define SOAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6061b01d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Compute training, validation and testing data\n",
    "#Get training data for the FPS-sorted training set\n",
    "ytF = []\n",
    "for ifrm, frm in enumerate(train_set_FPS):\n",
    "    ytF.append(frm.info['energy'])\n",
    "ytrain_FPS = np.array(ytF)\n",
    "\n",
    "#Get true energies and forces for validation set\n",
    "yvt = []\n",
    "fvt = []\n",
    "\n",
    "for frm in val_set:\n",
    "    yvt.append(frm.info['energy'])\n",
    "    fvt.append(frm.get_array('forces'))\n",
    "\n",
    "yval_true = np.array(yvt)\n",
    "fval_true = np.concatenate(fvt)\n",
    "\n",
    "#Get true energies and forces for test set\n",
    "ytt = []\n",
    "ftt = []\n",
    "\n",
    "for frm in test_set:\n",
    "    ytt.append(frm.info['energy'])\n",
    "    ftt.append(frm.get_array('forces'))\n",
    "\n",
    "ytest_true = np.array(ytt)\n",
    "ftest_true = np.concatenate(ftt)\n",
    "\n",
    "#get dressed atom energies for reduced training set\n",
    "y_dressed = {}\n",
    "for i,j in enumerate([1,6,7,8]):\n",
    "    y_dressed[j] = mlr.coef_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc767762",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "zeta=3\n",
    "hypers = dict(soap_type=\"PowerSpectrum\",\n",
    "              interaction_cutoff=6, #cutoff distance in angstroms\n",
    "              max_radial=9, #no. of radial basis functions\n",
    "              max_angular=6, #no. of angular basis functions\n",
    "              gaussian_sigma_constant=0.4, #sigma width (i.e. amount of 'smearing')\n",
    "              gaussian_sigma_type=\"Constant\",\n",
    "              cutoff_function_type=\"RadialScaling\",\n",
    "              cutoff_smooth_width=0.5,\n",
    "              cutoff_function_parameters=\n",
    "                    dict(\n",
    "                            rate=1,\n",
    "                            scale=2,\n",
    "                            exponent=4\n",
    "                        ),\n",
    "              radial_basis=\"GTO\",\n",
    "              normalize=True,\n",
    "              optimization=\n",
    "                    dict(\n",
    "                            Spline=dict(\n",
    "                               accuracy=1.0e-05\n",
    "                            )\n",
    "                        ),\n",
    "              compute_gradients=False \n",
    "              )\n",
    "soap = SphericalInvariants(**hypers) #redefine soap with new parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308a0cf",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Test without gradients\n",
    "Model seems to perform poorly with not much explanation why... should try and recreate model using `compute_gradients = False ` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d175cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "hypers[\"compute_gradients\"] = False\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e444c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get features\n",
    "start = time()\n",
    "print(\"Calculating features...\")\n",
    "train_set_FPS_feats = soap.transform(train_set_FPS)\n",
    "print(\"Time taken =\", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc995f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define kernel\n",
    "kernel = Kernel(soap, name='GAP', zeta=zeta, target_type='Structure', kernel_type='Sparse') #Define Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eec095",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "print(\"Computing kernel...\")\n",
    "Knm = kernel(train_set_FPS_feats, X_sparse_FPS)\n",
    "print(\"Time taken = \", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f15261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save kernel\n",
    "np.save('model_data/Knm_kernel_no_grad', Knm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03469c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Knm = np.load('model_data/Knm_kernel_no_grad.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b82ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train GAP model\n",
    "y_dressed = {} #create dressed atom energies for reduced training set\n",
    "for i,j in enumerate([1,6,7,8]):\n",
    "    y_dressed[j] = mlr.coef_[i]\n",
    "print(\"Training GAP model...\")\n",
    "start = time()\n",
    "full_model = train_gap_model(kernel, train_set_FPS, Knm, X_sparse_FPS, ytrain_FPS, y_dressed, \n",
    "                        grad_train=None, lambdas=[0.1, 1], jitter=1e-9, \n",
    "                        solver = 'RKHS')\n",
    "print(\"Time taken :\", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers[\"compute_gradients\"] = True\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ceaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict energies and forces for validation set\n",
    "npred=1000\n",
    "yvp = []\n",
    "fvp = []\n",
    "\n",
    "for frm in tqdm(val_set[:npred], desc = \"Making predictions for validation set...\", leave=False):\n",
    "    manager_val = soap.transform(frm)\n",
    "    yvp.append(full_model.predict(manager_val))\n",
    "    fvp.append(full_model.predict_forces(manager_val))\n",
    "\n",
    "yval_pred = np.array(yvp).flatten()\n",
    "fval_pred = np.concatenate(fvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,p = plt.subplots(1,2, figsize = (10, 5))\n",
    "p[0].scatter((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1),\n",
    "             (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))\n",
    "p[0].set_title('Energies (eV)')\n",
    "p[0].set()\n",
    "p[1].scatter(fval_true.flatten()[:npred], fval_pred.flatten()[:npred])\n",
    "p[1].set_title(r'Forces (ev/$\\AA$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,p = plt.subplots(1,2,figsize=(12,5))\n",
    "p[0].hist(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2)\n",
    "p[0].set_title('Distr. of Squared Energy Error')\n",
    "p[0].set_yscale('log')\n",
    "p[1].hist((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2)\n",
    "p[1].set_title('Distr. of Squared Forces Error')\n",
    "p[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_energy = np.sqrt(np.mean(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_forces = np.sqrt(np.mean((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_energy, rmse_forces) #0.1, 1 lambas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb12ad",
   "metadata": {},
   "source": [
    "## Test by using FPS-sorted configurations\n",
    "It seems like the PCovCUR-selected configurations (8400 total) has 4807 original structures and 3593 dupicates. The first dupicate occurred after 2678 selections. This occurred even though `recompute_every` was set to 1 for the first 3000 selections, and the SOAP vector has a length of 5670.\n",
    "I will therefore try and use FPS-sorted structures for the model and recompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ed527",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Redefine hyperparameters and SOAP\n",
    "hypers[\"compute_gradients\"] = False\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b1850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 8400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c55654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute feature matrices\n",
    "print(\"Computing feature matrices...\")\n",
    "start=time()\n",
    "manager_train = soap.transform(train_set_FPS[:ntrain]) #calculating features\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa70d20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use an FPS filter to obtain desired number of sparse points per species\n",
    "nh = 1778\n",
    "nc = 1467\n",
    "nn = 1467\n",
    "no = 1778\n",
    "nsparse    = {1: nh, 6: nc, 7: nn, 8: no} #Select number of sparse environemnts per species\n",
    "compressor = FPSFilter(soap,nsparse,act_on='sample per species') #Filter to sparsify full feature matrix\n",
    "print(\"Sparsifying training set...\")\n",
    "start=time()\n",
    "X_sparse_FPS = compressor.select_and_filter(manager_train) #Apply filter to training set\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277ec57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_obj('model_data/X_sparse_FPS.json', X_sparse_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse_FPS = load_obj('model_data/X_sparse_FPS.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df3b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define kernel and redefine hypers \n",
    "hypers[\"compute_gradients\"] = True #we want to compute gradients (forces) for the kernel\n",
    "soap = SphericalInvariants(**hypers)\n",
    "kernel = Kernel(soap, name='GAP', zeta=zeta, target_type='Structure', kernel_type='Sparse') #Define Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a4993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute kernel\n",
    "start=time()\n",
    "Knm_FPS = compute_KNM(tqdm(train_set_FPS[:ntrain], desc=\"Compute KNM\", leave=False), X_sparse_FPS, kernel, soap)\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8649d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save kernel\n",
    "np.save('model_data/Knm_kernel_FPS', Knm_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "Knm_FPS = np.load('model_data/Knm_kernel_FPS.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train GAP model\n",
    "y_dressed = {} #create dressed atom energies for reduced training set\n",
    "for i,j in enumerate([1,6,7,8]):\n",
    "    y_dressed[j] = mlr.coef_[i]\n",
    "print(\"Training GAP model...\")\n",
    "start = time()\n",
    "full_model = train_gap_model(kernel, train_set_FPS[:ntrain], Knm_FPS, X_sparse_FPS, ytrain_FPS[:ntrain], y_dressed, \n",
    "                        grad_train=-get_forces(train_set_FPS[:ntrain]), lambdas=[0.055,3.25], jitter=1e-9, \n",
    "                        solver = 'RKHS')\n",
    "print(\"Time taken:\", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_obj('model_data/full_GAP_model_FPS_0.055_3.25.json', full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cabd3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = load_obj('model_data/full_GAP_model_FPS_0.1_10.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262213b",
   "metadata": {},
   "source": [
    "### Predict on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2bfb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict energies and forces for validation set\n",
    "npred=1000\n",
    "yvp = []\n",
    "fvp = []\n",
    "\n",
    "for frm in tqdm(val_set[:npred], desc = \"Making predictions for validation set...\", leave=False):\n",
    "    manager_val = soap.transform(frm)\n",
    "    yvp.append(full_model.predict(manager_val))\n",
    "    fvp.append(full_model.predict_forces(manager_val))\n",
    "\n",
    "yval_pred = np.array(yvp).flatten()\n",
    "fval_pred = np.concatenate(fvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predicted vs. actual energies and forces\n",
    "f,p = plt.subplots(1,2, figsize = (10, 5))\n",
    "p[0].scatter((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1),\n",
    "             (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))\n",
    "p[0].set_title('Energies (eV)')\n",
    "p[0].set()\n",
    "p[1].scatter(fval_true.flatten()[:npred], fval_pred.flatten()[:npred])\n",
    "p[1].set_title(r'Forces (ev/$\\AA$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot distribution of energy and force errors\n",
    "f,p = plt.subplots(1,2,figsize=(12,5))\n",
    "p[0].hist(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2)\n",
    "p[0].set_title('Distr. of Squared Energy Error')\n",
    "p[0].set_yscale('log')\n",
    "p[1].hist((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2)\n",
    "p[1].set_title('Distr. of Squared Forces Error')\n",
    "p[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439502eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_energy = np.sqrt(np.mean(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea4efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_forces = np.sqrt(np.mean((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76515d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_energy, rmse_forces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd69ce",
   "metadata": {},
   "source": [
    "### Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict energies and forces for test set\n",
    "npred=1000\n",
    "ytp = []\n",
    "ftp = []\n",
    "\n",
    "for frm in tqdm(test_set[:npred], desc = \"Making predictions for validation set...\", leave=False):\n",
    "    manager_test = soap.transform(frm)\n",
    "    ytp.append(full_model.predict(manager_test))\n",
    "    ftp.append(full_model.predict_forces(manager_test))\n",
    "\n",
    "ytest_pred = np.array(ytp).flatten()\n",
    "ftest_pred = np.concatenate(ftp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da9171",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest_pred = np.array(ytp).flatten()\n",
    "ftest_pred = np.concatenate(ftp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predicted vs. actual energies and forces\n",
    "f,p = plt.subplots(1,2, figsize = (10, 5), dpi=200)\n",
    "p[0].scatter((ytest_true[:npred] - mlr.predict(X_test[:npred]))/np.sum(X_test[:npred],axis=1),\n",
    "             (ytest_pred[:npred] - mlr.predict(X_test[:npred]))/np.sum(X_test[:npred],axis=1), s=8)\n",
    "p[0].plot([-0.4,0.4],[-0.4, 0.4], color='red')\n",
    "p[0].set_title(r'Baselined Energies')\n",
    "p[0].set_xlabel('True energy (eV)')\n",
    "p[0].set_ylabel('Predicted energy (eV)')\n",
    "p[1].scatter(ftest_true.flatten()[:npred], ftest_pred.flatten()[:npred], s=8)\n",
    "p[1].plot([-3,4],[-3, 4], color='red')\n",
    "p[1].set_title(r'Forces')\n",
    "p[1].set_xlabel('True force (ev / $\\AA$)')\n",
    "p[1].set_ylabel('Predicted force (ev / $\\AA$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot distribution of energy and force errors\n",
    "f,p = plt.subplots(1,2,figsize=(12,5), dpi=200)\n",
    "p[0].hist(((ytest_true[:npred] - mlr.predict(X_test[:npred]))/np.sum(X_test[:npred],axis=1) \n",
    "           - (ytest_pred[:npred] - mlr.predict(X_test[:npred]))/np.sum(X_test[:npred],axis=1))**2, bins=15)\n",
    "p[0].set_title('Distribution of Squared Energy Error')\n",
    "p[0].set_yscale('log')\n",
    "p[0].set_xlabel('Squared error (eV)')\n",
    "p[0].set_ylabel('Frequency')\n",
    "p[0].ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "p[1].hist((ftest_true.flatten()[:npred] - ftest_pred.flatten()[:npred])**2, bins=15)\n",
    "p[1].set_title('Distribution of Squared Force Error')\n",
    "p[1].set_xlabel('Squared error (eV / $\\AA$)')\n",
    "p[1].set_ylabel('Frequency')\n",
    "p[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c62ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_energy = np.sqrt(np.mean(\n",
    "    ((ytest_true[:npred] - mlr.predict(X_test[:npred]))/np.sum(X_test[:npred],axis=1) \n",
    "     - (ytest_pred[:npred] - mlr.predict(X_test[:npred]))/np.sum(X_test[:npred],axis=1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c28b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_forces = np.sqrt(np.mean((ftest_true.flatten()[:npred] - ftest_pred.flatten()[:npred])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE energy: \", np.round(rmse_energy, 5)*1000, \"meV\")\n",
    "print(\"RMSE forces: \", np.round(rmse_forces, 5)*1000, \"meV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1333e",
   "metadata": {},
   "source": [
    "### Optimise regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9bef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop for optimising regularization parameters\n",
    "npred=100\n",
    "for er in np.linspace(0.01, 0.1, 5):\n",
    "    for fr in np.linspace(1, 10, 5):\n",
    "        print(\"Testing for energy reg\", er, \"and force reg\", fr)\n",
    "        start=time()\n",
    "        full_model = train_gap_model(kernel, train_set_FPS, Knm_FPS, X_sparse_FPS, ytrain_FPS, y_dressed, \n",
    "                        grad_train=-get_forces(train_set_FPS), lambdas=[er,fr], jitter=1e-9, \n",
    "                        solver = 'RKHS')\n",
    "        yvp = []\n",
    "        fvp = []\n",
    "        for frm in tqdm(val_set[:npred], desc = \"Making predictions for validation set...\", leave=False):\n",
    "            manager_val = soap.transform(frm)\n",
    "            yvp.append(full_model.predict(manager_val))\n",
    "            fvp.append(full_model.predict_forces(manager_val))\n",
    "\n",
    "        yval_pred = np.array(yvp).flatten()\n",
    "        fval_pred = np.concatenate(fvp)\n",
    "        rmse_energy = np.sqrt(np.mean(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2))\n",
    "        rmse_forces = np.sqrt(np.mean((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2))\n",
    "        print(\"Energy RMSE:\", rmse_energy, \"  Force RMSE:\", rmse_forces, \"   Time taken:\", time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57657f5",
   "metadata": {},
   "source": [
    "## Pseudo-active learning curve for FPS-selected structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ceba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "hypers[\"compute_gradients\"] = False\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3809dac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set_FPS_feats = get_features(train_set_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_feat = get_features(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388077b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_FPS = np.zeros((len(train_set_FPS),4),dtype=int)\n",
    "y_train_FPS = np.zeros(len(train_set_FPS))\n",
    "for ifrm, frm in enumerate(train_set_FPS):\n",
    "    symbols=frm.get_atomic_numbers()\n",
    "    y_train_FPS[ifrm]=(frm.info['energy'])\n",
    "    X_train_FPS[ifrm]=[len(np.where(symbols == sp)[0]) for sp in [1,6,7,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yred_train_FPS = y_train_FPS/np.sum(X_train_FPS,axis=1)-mlr.predict(X_train_FPS)/np.sum(X_train_FPS,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2184c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = []\n",
    "errors = []\n",
    "for nstruct in [2000,4000,8000,12000,16000,20000,22617]:\n",
    "    K = np.dot(train_set_FPS_feats[:nstruct], train_set_FPS_feats[:nstruct].T)**zeta #compute kernel matrix for training\n",
    "    Kval = np.dot(val_feat,train_set_FPS_feats[:nstruct].T)**zeta #compute kernel matrix for validation\n",
    "    KRR = KernelRidge(kernel='precomputed',alpha = 1e-9)\n",
    "    KRR.fit(K,yred_train_FPS[:nstruct])\n",
    "    err = np.std((yval_true - mlr.predict(X_val))/np.sum(X_val, axis=1) - KRR.predict(Kval))\n",
    "    print(nstruct, err)\n",
    "    structures.append(nstruct)\n",
    "    errors.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "plt.plot(structures,errors)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea6b2d",
   "metadata": {},
   "source": [
    "## Test with more structures\n",
    "From the above test, it seems like the learning curve is not saturated at 8400 structures. More than that, it is likely that more structures are required to saturate the learning curve for forces than for energies. The reason for this is likely because, as Edgar put it, \"the structural variance in local atomic environments is larger than that in structures (where differences between constituent environments are to some degree averaged out), and energies are a structural property whereas forces are an environmental one.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0760ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85a384f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "hypers[\"compute_gradients\"] = False\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d7413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature matrices\n",
    "print(\"Computing feature matrices...\")\n",
    "start=time()\n",
    "manager_train = soap.transform(train_set_FPS[:ntrain]) #calculating features\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97229b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an FPS filter to obtain desired number of sparse points per species\n",
    "nh = 1778\n",
    "nc = 1467\n",
    "nn = 1467\n",
    "no = 1778\n",
    "nsparse    = {1: nh, 6: nc, 7: nn, 8: no} #Select number of sparse environemnts per species\n",
    "compressor = FPSFilter(soap,nsparse,act_on='sample per species') #Filter to sparsify full feature matrix\n",
    "print(\"Sparsifying training set...\")\n",
    "start=time()\n",
    "X_sparse_FPS = compressor.select_and_filter(manager_train) #Apply filter to training set\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7353a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_obj('raw_data/X_sparse_12k.json', X_sparse_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6005446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse_FPS = load_obj('raw_data/X_sparse_12k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6340b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define kernel and redefine hypers \n",
    "hypers[\"compute_gradients\"] = True #we want to compute gradients (forces) for the kernel\n",
    "soap = SphericalInvariants(**hypers)\n",
    "kernel = Kernel(soap, name='GAP', zeta=zeta, target_type='Structure', kernel_type='Sparse') #Define Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc59b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute kernel\n",
    "start=time()\n",
    "Knm_FPS = compute_KNM(tqdm(train_set_FPS[:ntrain], desc=\"Compute KNM\", leave=False), X_sparse_FPS, kernel, soap)\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c752e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save kernel\n",
    "np.save('raw_data/Knm_kernel_12k', Knm_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "Knm_FPS = np.load('raw_data/Knm_kernel_12k.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2028fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train GAP model\n",
    "y_dressed = {} #create dressed atom energies for reduced training set\n",
    "for i,j in enumerate([1,6,7,8]):\n",
    "    y_dressed[j] = mlr.coef_[i]\n",
    "print(\"Training GAP model...\")\n",
    "start = time()\n",
    "full_model = train_gap_model(kernel, train_set_FPS[:ntrain], Knm_FPS, X_sparse_FPS, ytrain_FPS, y_dressed, \n",
    "                        grad_train=-get_forces(train_set_FPS[:ntrain]), lambdas=[0.055,3.25], jitter=1e-9, \n",
    "                        solver = 'RKHS')\n",
    "print(\"Time taken:\", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict energies and forces for validation set\n",
    "npred=1000\n",
    "yvp = []\n",
    "fvp = []\n",
    "\n",
    "for frm in tqdm(val_set[:npred], desc = \"Making predictions for validation set...\", leave=False):\n",
    "    manager_val = soap.transform(frm)\n",
    "    yvp.append(full_model.predict(manager_val))\n",
    "    fvp.append(full_model.predict_forces(manager_val))\n",
    "\n",
    "yval_pred = np.array(yvp).flatten()\n",
    "fval_pred = np.concatenate(fvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predicted vs. actual energies and forces\n",
    "f,p = plt.subplots(1,2, figsize = (10, 5))\n",
    "p[0].scatter((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1),\n",
    "             (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))\n",
    "p[0].set_title('Energies (eV)')\n",
    "p[0].set()\n",
    "p[1].scatter(fval_true.flatten()[:npred], fval_pred.flatten()[:npred])\n",
    "p[1].set_title(r'Forces (ev/$\\AA$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dcf831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot distribution of energy and force errors\n",
    "f,p = plt.subplots(1,2,figsize=(12,5))\n",
    "p[0].hist(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2)\n",
    "p[0].set_title('Distr. of Squared Energy Error')\n",
    "p[0].set_yscale('log')\n",
    "p[1].hist((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2)\n",
    "p[1].set_title('Distr. of Squared Forces Error')\n",
    "p[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96754618",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_energy = np.sqrt(np.mean(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63326a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_forces = np.sqrt(np.mean((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e36ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_energy, rmse_forces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f9c3ab",
   "metadata": {},
   "source": [
    "## Test with more sparse points\n",
    "For the same reasoning as no. of structures, it might be better to increase the number of sparse points per species in order to improve force predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 8400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26beed3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "hypers[\"compute_gradients\"] = False\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06debde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature matrices\n",
    "print(\"Computing feature matrices...\")\n",
    "start=time()\n",
    "manager_train = soap.transform(train_set_FPS[:ntrain]) #calculating features\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1e30bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an FPS filter to obtain desired number of sparse points per species\n",
    "nh = 2500\n",
    "nc = 2500\n",
    "nn = 2500\n",
    "no = 2500\n",
    "nsparse    = {1: nh, 6: nc, 7: nn, 8: no} #Select number of sparse environemnts per species\n",
    "compressor = FPSFilter(soap,nsparse,act_on='sample per species') #Filter to sparsify full feature matrix\n",
    "print(\"Sparsifying training set...\")\n",
    "start=time()\n",
    "X_sparse_FPS = compressor.select_and_filter(manager_train) #Apply filter to training set\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e6844",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_obj('raw_data/X_sparse_2500_ps.json', X_sparse_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24106a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse_FPS = load_obj('raw_data/X_sparse_2500_ps.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define kernel and redefine hypers \n",
    "hypers[\"compute_gradients\"] = True #we want to compute gradients (forces) for the kernel\n",
    "soap = SphericalInvariants(**hypers)\n",
    "kernel = Kernel(soap, name='GAP', zeta=zeta, target_type='Structure', kernel_type='Sparse') #Define Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76acfabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute kernel\n",
    "start=time()\n",
    "Knm_FPS = compute_KNM(tqdm(train_set_FPS[:ntrain], desc=\"Compute KNM\", leave=False), X_sparse_FPS, kernel, soap)\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786eb694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save kernel\n",
    "np.save('raw_data/Knm_kernel_2500_ps', Knm_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cfc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Knm_FPS = np.load('raw_data/Knm_kernel_2500_ps.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede6f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train GAP model\n",
    "y_dressed = {} #create dressed atom energies for reduced training set\n",
    "for i,j in enumerate([1,6,7,8]):\n",
    "    y_dressed[j] = mlr.coef_[i]\n",
    "print(\"Training GAP model...\")\n",
    "start = time()\n",
    "full_model = train_gap_model(kernel, train_set_FPS[:ntrain], Knm_FPS, X_sparse_FPS, ytrain_FPS[:ntrain], y_dressed, \n",
    "                        grad_train=-get_forces(train_set_FPS[:ntrain]), lambdas=[0.055,3.25], jitter=1e-9, \n",
    "                        solver = 'RKHS')\n",
    "print(\"Time taken:\", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e7f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict energies and forces for validation set\n",
    "npred=1000\n",
    "yvp = []\n",
    "fvp = []\n",
    "\n",
    "for ifrm, frm in enumerate(tqdm(val_set[:npred], desc = \"Making predictions for validation set...\", leave=False)):\n",
    "    manager_val = soap.transform(frm)\n",
    "    yvp.append(full_model.predict(manager_val))\n",
    "    fvp.append(full_model.predict_forces(manager_val))\n",
    "    if ifrm % 100 == 0:\n",
    "        print(ifrm)\n",
    "\n",
    "yval_pred = np.array(yvp).flatten()\n",
    "fval_pred = np.concatenate(fvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3697eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predicted vs. actual energies and forces\n",
    "f,p = plt.subplots(1,2, figsize = (10, 5))\n",
    "p[0].scatter((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1),\n",
    "             (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))\n",
    "p[0].set_title('Energies (eV)')\n",
    "p[0].set()\n",
    "p[1].scatter(fval_true.flatten()[:npred], fval_pred.flatten()[:npred])\n",
    "p[1].set_title(r'Forces (ev/$\\AA$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot distribution of energy and force errors\n",
    "f,p = plt.subplots(1,2,figsize=(12,5))\n",
    "p[0].hist(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2)\n",
    "p[0].set_title('Distr. of Squared Energy Error')\n",
    "p[0].set_yscale('log')\n",
    "p[1].hist((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2)\n",
    "p[1].set_title('Distr. of Squared Forces Error')\n",
    "p[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_energy = np.sqrt(np.mean(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_forces = np.sqrt(np.mean((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7873c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_energy, rmse_forces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce234f9",
   "metadata": {},
   "source": [
    "## Effect of sparse points on GAP accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c530647e",
   "metadata": {},
   "source": [
    "From above, we can see that the errors using 2500 sparse points per species are:\n",
    "- 5.1 meV for energy predictions\n",
    "- 349 meV for force predictions\n",
    "\n",
    "Using the \"standard number of sparse points (~1600 per species), the errors are:\n",
    "- 6.5 meV for energy predictions\n",
    "- 440 meV for force predictions\n",
    "\n",
    "We will now try and reduce the number of sparse points further to see the effect it has on the accuracy of predictions. If we can obtain similar accuracy with fewer sparse points this would lighten the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 8400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b5b8cf",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "hypers[\"compute_gradients\"] = False\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d6e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature matrices\n",
    "print(\"Computing feature matrices...\")\n",
    "start=time()\n",
    "manager_train = soap.transform(train_set_FPS[:ntrain]) #calculating features\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ac87f",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loop for testing dependency of number of sparse points on GAP model accuracy\n",
    "rmses = np.zeros((3,3))\n",
    "for ins, ns in enumerate([700, 1000, 1300]):\n",
    "    print(\"Testing for \", ns, \"sparse points per species\")\n",
    "    start=time()\n",
    "    #Define hyperparameters and SOAP\n",
    "    hypers[\"compute_gradients\"] = False\n",
    "    soap = SphericalInvariants(**hypers)\n",
    "    \n",
    "    #Calculate X_sparse\n",
    "    nsparse    = {1: ns, 6: ns, 7: ns, 8: ns} #Select number of sparse environemnts per species\n",
    "    compressor = FPSFilter(soap,nsparse,act_on='sample per species') #Filter to sparsify full feature matrix\n",
    "    print(\"Sparsifying training set...\")\n",
    "    X_sparse_FPS = compressor.select_and_filter(manager_train) #Apply filter to training set\n",
    "    \n",
    "    #Define kernel and redefine hypers \n",
    "    hypers[\"compute_gradients\"] = True #we want to compute gradients (forces) for the kernel\n",
    "    soap = SphericalInvariants(**hypers)\n",
    "    kernel = Kernel(soap, name='GAP', zeta=zeta, target_type='Structure', kernel_type='Sparse') #Define Kernel\n",
    "    \n",
    "    #Compute kernel\n",
    "    print(\"Computing kernel...\")\n",
    "    Knm_FPS = compute_KNM(tqdm(train_set_FPS[:ntrain], desc=\"Computing KNM\", leave=False), X_sparse_FPS, kernel, soap)\n",
    "    \n",
    "    #Train model\n",
    "    print(\"Training model...\")\n",
    "    full_model = train_gap_model(kernel, train_set_FPS[:ntrain], Knm_FPS, X_sparse_FPS, ytrain_FPS[:ntrain], y_dressed, \n",
    "                        grad_train=-get_forces(train_set_FPS[:ntrain]), lambdas=[0.055,3.25], jitter=1e-9, \n",
    "                        solver = 'RKHS')\n",
    "    \n",
    "    #predict energies and forces for validation set\n",
    "    npred=1000\n",
    "    yvp = []\n",
    "    fvp = []\n",
    "    \n",
    "    print(\"Making predictions on validation set...\")\n",
    "    for ifrm, frm in enumerate(tqdm(val_set[:npred], desc = \"Making predictions for validation set...\", leave=False)):\n",
    "        manager_val = soap.transform(frm)\n",
    "        yvp.append(full_model.predict(manager_val))\n",
    "        fvp.append(full_model.predict_forces(manager_val))\n",
    "\n",
    "    yval_pred = np.array(yvp).flatten()\n",
    "    fval_pred = np.concatenate(fvp)\n",
    "    \n",
    "    #get energy and force rmses\n",
    "    rmse_energy = np.sqrt(np.mean(\n",
    "        ((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) \n",
    "         - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2))\n",
    "    rmse_force = np.sqrt(np.mean((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2))\n",
    "    \n",
    "    print(\"For\", nsparse, \"sparse points per species :\")\n",
    "    print(\"Energy RMSE:\", rmse_energy)\n",
    "    print(\"Force RMSE:\", rmse_force)\n",
    "    print(\"Total time taken for full test:\", time()-start)\n",
    "    \n",
    "    #Append info to numpy array\n",
    "    rmses[ins] = [ns, rmse_energy, rmse_force]\n",
    "\n",
    "#Save results\n",
    "np.save('raw_data/sparse_points_test', rmses)\n",
    "print(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297902f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('raw_data/sparse_points_test', rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061a2e3",
   "metadata": {},
   "source": [
    "## Effect of SOAP vector size on GAP accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c051a57",
   "metadata": {},
   "source": [
    "The large SOAP vector of 5670 severely reduces the speed of predictions, and so we will try and see how the accuracy of predictions is dependent on the size of the SOAP vector.\n",
    "\n",
    "We will first try and use Bayesian hyperparameter optimisation to see if we can get good results using a smaller vector (and to see if we can improve results significantly using this Bayesian optimisation).\n",
    "\n",
    "(We will reduce the SOAP vector to size 2520 by using nmax = 6 and lmax =6.\n",
    "\n",
    "We will then reduce it to size 1800 by using nmax = 6 and lmax = 4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82e5a63",
   "metadata": {},
   "source": [
    "### Bayesian optimisation of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf685bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 8400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da82c4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "hypers[\"compute_gradients\"] = False\n",
    "hypers[\"interaction_cutoff\"] = 4\n",
    "hypers[\"max_radial\"] = 6\n",
    "hypers[\"max_angular\"] = 6\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734462d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_FPS = np.zeros((len(train_set_FPS),4),dtype=int)\n",
    "y_train_FPS = np.zeros(len(train_set_FPS))\n",
    "for ifrm, frm in enumerate(train_set_FPS):\n",
    "    symbols=frm.get_atomic_numbers()\n",
    "    y_train_FPS[ifrm]=(frm.info['energy'])\n",
    "    X_train_FPS[ifrm]=[len(np.where(symbols == sp)[0]) for sp in [1,6,7,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d77cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_structures = train_set_FPS[:10000]\n",
    "test_structures = val_set.copy()\n",
    "y_train = y_train_FPS[:10000]-mlr.predict(X_train_FPS[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af34b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a searchspace\n",
    "space = [Real(10**-6, 10**1, \"log-uniform\", name='alpha'),\n",
    "        Real(1.0,3.0, \"uniform\", name=\"scale\"),\n",
    "        Real(3.0,7.0, \"uniform\", name=\"interaction_cutoff\"),\n",
    "        Real(0.05,0.6, \"uniform\", name=\"gaussian_sigma_constant\"),\n",
    "        Real(0.1,20.0, \"uniform\", name=\"exponent\"),\n",
    "        Real(0.1,20.0, \"uniform\", name=\"rate\")\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3f95e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#define the SOAP objective\n",
    "feature_gen_time = 0\n",
    "hyper_opt_time = 0\n",
    "model_fit_time = 0\n",
    "\n",
    "\n",
    "@use_named_args(space)\n",
    "def soap_objective(**params):\n",
    "    global feature_gen_time\n",
    "    global hyper_opt_time\n",
    "    global model_fit_time\n",
    "    \n",
    "    new_params = params.copy()\n",
    "    new_hypers = hypers.copy()\n",
    "    \n",
    "    #modify SOAP hypers\n",
    "    new_hypers[\"interaction_cutoff\"] = new_params[\"interaction_cutoff\"]\n",
    "    new_hypers[\"gaussian_sigma_constant\"] = new_params[\"gaussian_sigma_constant\"]\n",
    "    new_hypers[\"cutoff_function_parameters\"] = {\"rate\":new_params[\"rate\"],\n",
    "                                               \"exponent\":new_params[\"exponent\"],\n",
    "                                               \"scale\":new_params[\"scale\"]}\n",
    "    soap = SphericalInvariants(**new_hypers)\n",
    "    \n",
    "    #obtain optimal radial basis\n",
    "    start_time = time()\n",
    "    new_hypers = get_optimal_radial_basis_hypers_parallel(new_hypers,train_structures,num_cores=-1,\n",
    "                                                          expanded_max_radial=20)\n",
    "    hyper_opt_time += time() - start_time\n",
    "    \n",
    "    #update model parameters\n",
    "    model.set_params(alpha=new_params[\"alpha\"])\n",
    "    \n",
    "    #calculate SOAP features\n",
    "    start_time = time()\n",
    "    X_train = get_features_parallel(train_structures, bsize=200, n_cores=60)\n",
    "    feature_gen_time += time() - start_time\n",
    "    \n",
    "    #Model training and scoring\n",
    "    start_time = time()\n",
    "    #in production it might make sense to increase the k-fold to 5, given that bayes opt makes the noise free asummption\n",
    "    #splits = list(GroupKFold(n_splits=3).split(X_train,y_train)\n",
    "    score = -np.mean(cross_val_score(model, X_train, y_train, n_jobs=-1,\n",
    "                                    scoring=\"neg_mean_squared_error\"))\n",
    "    model_fit_time += time() - start_time\n",
    "    print(\"--eval--\")\n",
    "    \n",
    "    #return n-fold cross val\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a9ce6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Perform Bayseian hyperparameter optimisation\n",
    "feature_gen_time = 0\n",
    "hyper_opt_time = 0\n",
    "model_fit_time = 0\n",
    "\n",
    "model = Ridge()\n",
    "\n",
    "# We provide a reasonable first guess.\n",
    "# Parameters reported in 10.1039/C9CP04489B Engel et al.  \n",
    "# model alpha, scale, cutoff, sigma, exponent, rate\n",
    "reasonable_guess = [1e-05,2.0,4.5,0.3,3,1]\n",
    "\n",
    "checkpoint_saver = CheckpointSaver(\"./checkpoint_solver.pkl\", compress=9)\n",
    "\n",
    "print(\"starting\")\n",
    "start_time_total = time()\n",
    "\n",
    "# provide search space, number of total objective function calls, a sead, an initial guess (optional)\n",
    "# the number of jobs to optimize the aquisition function (LBFGS) and a callback (checkpoint saver)\n",
    "\n",
    "#---------- actual optimization is called here -------------\n",
    "\n",
    "res_gp = gp_minimize(soap_objective, space, n_calls=100, random_state=0,\\\n",
    "                     x0=reasonable_guess, n_jobs=-1, callback=[checkpoint_saver])\n",
    "\n",
    "#------------------------------------------------------------\n",
    "\n",
    "print(\"--- 25 steps took %.0f seconds ---\" % (time() - start_time_total))\n",
    "print(\"--- feature generation took %.0f seconds ---\" % (feature_gen_time))\n",
    "print(\"--- model fitting took %.0f seconds ---\" % (model_fit_time))\n",
    "print(\"--- hyper optimization took %.0f seconds ---\" % (hyper_opt_time))\n",
    "\n",
    "dump(res_gp, \"solver_final.pkl\")\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150,figsize=(5.,3.))\n",
    "_ = plot_convergence(res_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2365b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also load the last OptimizeResult\n",
    "res_gp = load(\"checkpoint_solver.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0cee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model alpha, scale, cutoff, sigma, exponent, rate\n",
    "res_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model alpha, scale, cutoff, sigma, exponent, rate\n",
    "hypers[\"interaction_cutoff\"] = res_gp.x[2]\n",
    "hypers[\"gaussian_sigma_constant\"] = res_gp.x[3]\n",
    "hypers[\"cutoff_function_parameters\"] = {\"rate\":res_gp.x[5],\n",
    "                                               \"exponent\":res_gp.x[4],\n",
    "                                               \"scale\":res_gp.x[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1d40ce",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "hypers[\"compute_gradients\"] = False\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05d4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature matrices\n",
    "print(\"Computing feature matrices...\")\n",
    "start=time()\n",
    "manager_train = soap.transform(train_set_FPS[:ntrain]) #calculating features\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7871627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an FPS filter to obtain desired number of sparse points per species\n",
    "nh = 1300\n",
    "nc = 1300\n",
    "nn = 1300\n",
    "no = 1300\n",
    "nsparse    = {1: nh, 6: nc, 7: nn, 8: no} #Select number of sparse environemnts per species\n",
    "compressor = FPSFilter(soap,nsparse,act_on='sample per species') #Filter to sparsify full feature matrix\n",
    "print(\"Sparsifying training set...\")\n",
    "start=time()\n",
    "X_sparse_FPS = compressor.select_and_filter(manager_train) #Apply filter to training set\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd0c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_obj('raw_data/X_sparse_bayes_hypers.json', X_sparse_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647cb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse_FPS = load_obj('raw_data/X_sparse_bayes_hypers.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b6ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define kernel and redefine hypers \n",
    "hypers[\"compute_gradients\"] = True #we want to compute gradients (forces) for the kernel\n",
    "soap = SphericalInvariants(**hypers)\n",
    "kernel = Kernel(soap, name='GAP', zeta=zeta, target_type='Structure', kernel_type='Sparse') #Define Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute kernel\n",
    "start=time()\n",
    "Knm_FPS = compute_KNM(tqdm(train_set_FPS[:ntrain], desc=\"Compute KNM\", leave=False), X_sparse_FPS, kernel, soap)\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save kernel\n",
    "np.save('raw_data/Knm_kernel_bayes_hypers', Knm_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a4abe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Knm_FPS = np.load('raw_data/Knm_kernel_bayes_hypers.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6871d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test model with optimal hyperparameters and previously-determined optimal regularizers\n",
    "print(\"Training GAP model...\")\n",
    "start = time()\n",
    "full_model = train_gap_model(kernel, train_set_FPS[:ntrain], Knm_FPS, X_sparse_FPS, ytrain_FPS[:ntrain], y_dressed, \n",
    "                        grad_train=-get_forces(train_set_FPS[:ntrain]), lambdas=[0.055,3.25], jitter=1e-9, \n",
    "                        solver = 'RKHS')\n",
    "print(\"Time taken:\", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740316f7",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#predict energies and forces for validation set\n",
    "npred=1000\n",
    "yvp = []\n",
    "fvp = []\n",
    "\n",
    "for ifrm, frm in enumerate(tqdm(val_set[:npred], desc = \"Making predictions for validation set...\", leave=False)):\n",
    "    manager_val = soap.transform(frm)\n",
    "    yvp.append(full_model.predict(manager_val))\n",
    "    fvp.append(full_model.predict_forces(manager_val))\n",
    "\n",
    "yval_pred = np.array(yvp).flatten()\n",
    "fval_pred = np.concatenate(fvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d86b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predicted vs. actual energies and forces\n",
    "f,p = plt.subplots(1,2, figsize = (10, 5))\n",
    "p[0].scatter((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1),\n",
    "             (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))\n",
    "p[0].set_title('Energies (eV)')\n",
    "p[0].set()\n",
    "p[1].scatter(fval_true.flatten()[:npred], fval_pred.flatten()[:npred])\n",
    "p[1].set_title(r'Forces (ev/$\\AA$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9a04f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot distribution of energy and force errors\n",
    "f,p = plt.subplots(1,2,figsize=(12,5))\n",
    "p[0].hist(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2)\n",
    "p[0].set_title('Distr. of Squared Energy Error')\n",
    "p[0].set_yscale('log')\n",
    "p[1].hist((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2)\n",
    "p[1].set_title('Distr. of Squared Forces Error')\n",
    "p[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1fbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_energy = np.sqrt(np.mean(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f98b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_forces = np.sqrt(np.mean((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9c03cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_energy, rmse_forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b70453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test with many different regularizers\n",
    "for ereg in np.logspace(-4,1,6):\n",
    "    for freg in np.logspace(int(np.log10(ereg))+1, 2, 2-int(np.log10(ereg))):\n",
    "        print(\"Training GAP model on energy reg\", ereg, \"and forces reg\", freg)\n",
    "        full_model = train_gap_model(kernel, train_set_FPS[:ntrain], Knm_FPS, X_sparse_FPS, ytrain_FPS[:ntrain], y_dressed, \n",
    "                                grad_train=-get_forces(train_set_FPS[:ntrain]), lambdas=[ereg,freg], jitter=1e-9, \n",
    "                                solver = 'RKHS')\n",
    "        npred=100\n",
    "        yvp = []\n",
    "        fvp = []\n",
    "\n",
    "        for ifrm, frm in enumerate(tqdm(val_set[:npred], desc = \"Making predictions for validation set...\", leave=False)):\n",
    "            manager_val = soap.transform(frm)\n",
    "            yvp.append(full_model.predict(manager_val))\n",
    "            fvp.append(full_model.predict_forces(manager_val))\n",
    "\n",
    "        yval_pred = np.array(yvp).flatten()\n",
    "        fval_pred = np.concatenate(fvp)\n",
    "\n",
    "        rmse_energy = np.sqrt(np.mean(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2))\n",
    "        rmse_forces = np.sqrt(np.mean((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2))\n",
    "        print(\"RMSE energy:\", rmse_energy*1000, \"meV/atom\")\n",
    "        print(\"RMSE forces:\", rmse_forces*1000, \"eV/angstrom\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59adc130",
   "metadata": {},
   "source": [
    "The errors using the \"optimal SOAP hyperparameters\" from Bayesian optimisation were actually very disappointing. Even when using regularization constants of 5e-6 and 5e-5 for energies/forces (optimal alpha from Bayesian optimisation) (resuls not shown here). So I will just use the previously determined optimal hyperparameters and test to see how errors with those differ when using a smaller nmax and lmax.\n",
    "\n",
    "For comparison, the errors when using the same (standard ~1600) sparse points and nmax = 9 with lmax = 6, the errors were:\n",
    "- Energies: 6.5 meV/atom\n",
    "- Forces: 440 meV/angstrom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803eb0d",
   "metadata": {},
   "source": [
    "### Test with nmax = 6 and lmax = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fc730",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 8400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baddbab7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "zeta=3\n",
    "hypers = dict(soap_type=\"PowerSpectrum\",\n",
    "              interaction_cutoff=6, #cutoff distance in angstroms\n",
    "              max_radial=9, #no. of radial basis functions\n",
    "              max_angular=6, #no. of angular basis functions\n",
    "              gaussian_sigma_constant=0.4, #sigma width (i.e. amount of 'smearing')\n",
    "              gaussian_sigma_type=\"Constant\",\n",
    "              cutoff_function_type=\"RadialScaling\",\n",
    "              cutoff_smooth_width=0.5,\n",
    "              cutoff_function_parameters=\n",
    "                    dict(\n",
    "                            rate=1,\n",
    "                            scale=2,\n",
    "                            exponent=4\n",
    "                        ),\n",
    "              radial_basis=\"GTO\",\n",
    "              normalize=True,\n",
    "              optimization=\n",
    "                    dict(\n",
    "                            Spline=dict(\n",
    "                               accuracy=1.0e-05\n",
    "                            )\n",
    "                        ),\n",
    "              compute_gradients=False \n",
    "              )\n",
    "soap = SphericalInvariants(**hypers) #redefine soap with new parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf06ef",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "hypers[\"compute_gradients\"] = False\n",
    "hypers[\"interaction_cutoff\"] = 6\n",
    "hypers[\"max_radial\"] = 6\n",
    "hypers[\"max_angular\"] = 6\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a801cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature matrices\n",
    "print(\"Computing feature matrices...\")\n",
    "start=time()\n",
    "manager_train = soap.transform(train_set_FPS[:ntrain]) #calculating features\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an FPS filter to obtain desired number of sparse points per species\n",
    "nh = 1778\n",
    "nc = 1467\n",
    "nn = 1467\n",
    "no = 1778\n",
    "nsparse    = {1: nh, 6: nc, 7: nn, 8: no} #Select number of sparse environemnts per species\n",
    "compressor = FPSFilter(soap,nsparse,act_on='sample per species') #Filter to sparsify full feature matrix\n",
    "print(\"Sparsifying training set...\")\n",
    "start=time()\n",
    "X_sparse_FPS = compressor.select_and_filter(manager_train) #Apply filter to training set\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9a7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_obj('raw_data/X_sparse_hypers_6_6.json', X_sparse_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c875c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse_FPS = load_obj('raw_data/X_sparse_hypers_6_6.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96781b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define kernel and redefine hypers \n",
    "hypers[\"compute_gradients\"] = True #we want to compute gradients (forces) for the kernel\n",
    "soap = SphericalInvariants(**hypers)\n",
    "kernel = Kernel(soap, name='GAP', zeta=zeta, target_type='Structure', kernel_type='Sparse') #Define Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ca4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute kernel\n",
    "start=time()\n",
    "Knm_FPS = compute_KNM(tqdm(train_set_FPS[:ntrain], desc=\"Compute KNM\", leave=False), X_sparse_FPS, kernel, soap)\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save kernel\n",
    "np.save('raw_data/Knm_kernel_hypers_6_6', Knm_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d369f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Knm_FPS = np.load('raw_data/Knm_kernel_hypers_6_6.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeebcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train GAP model\n",
    "print(\"Training GAP model...\")\n",
    "start = time()\n",
    "full_model = train_gap_model(kernel, train_set_FPS[:ntrain], Knm_FPS, X_sparse_FPS, ytrain_FPS[:ntrain], y_dressed, \n",
    "                        grad_train=-get_forces(train_set_FPS[:ntrain]), lambdas=[0.055,3.25], jitter=1e-9, \n",
    "                        solver = 'RKHS')\n",
    "print(\"Time taken:\", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78afb9",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#predict energies and forces for validation set\n",
    "npred=1000\n",
    "yvp = []\n",
    "fvp = []\n",
    "\n",
    "for ifrm, frm in enumerate(tqdm(val_set[:npred], desc = \"Making predictions for validation set...\", leave=False)):\n",
    "    manager_val = soap.transform(frm)\n",
    "    yvp.append(full_model.predict(manager_val))\n",
    "    fvp.append(full_model.predict_forces(manager_val))\n",
    "\n",
    "yval_pred = np.array(yvp).flatten()\n",
    "fval_pred = np.concatenate(fvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1635b951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predicted vs. actual energies and forces\n",
    "f,p = plt.subplots(1,2, figsize = (10, 5))\n",
    "p[0].scatter((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1),\n",
    "             (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))\n",
    "p[0].set_title('Energies (eV)')\n",
    "p[0].set()\n",
    "p[1].scatter(fval_true.flatten()[:npred], fval_pred.flatten()[:npred])\n",
    "p[1].set_title(r'Forces (ev/$\\AA$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e693de",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_energy = np.sqrt(np.mean(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b05af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_forces = np.sqrt(np.mean((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbbefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_energy, rmse_forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18494e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('results_data/hyper66_results.txt', np.array([rmse_energy, rmse_forces]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d03c5b7",
   "metadata": {},
   "source": [
    "### Test with nmax = 6 and lmax = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd0be3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "hypers[\"compute_gradients\"] = False\n",
    "hypers[\"interaction_cutoff\"] = 6\n",
    "hypers[\"max_radial\"] = 6\n",
    "hypers[\"max_angular\"] = 4\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251747b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature matrices\n",
    "print(\"Computing feature matrices...\")\n",
    "start=time()\n",
    "manager_train = soap.transform(train_set_FPS[:ntrain]) #calculating features\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ffd2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an FPS filter to obtain desired number of sparse points per species\n",
    "nh = 1778\n",
    "nc = 1467\n",
    "nn = 1467\n",
    "no = 1778\n",
    "nsparse    = {1: nh, 6: nc, 7: nn, 8: no} #Select number of sparse environemnts per species\n",
    "compressor = FPSFilter(soap,nsparse,act_on='sample per species') #Filter to sparsify full feature matrix\n",
    "print(\"Sparsifying training set...\")\n",
    "start=time()\n",
    "X_sparse_FPS = compressor.select_and_filter(manager_train) #Apply filter to training set\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8316b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_obj('raw_data/X_sparse_hypers_6_4.json', X_sparse_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a24b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse_FPS = load_obj('raw_data/X_sparse_hypers_6_4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define kernel and redefine hypers \n",
    "hypers[\"compute_gradients\"] = True #we want to compute gradients (forces) for the kernel\n",
    "soap = SphericalInvariants(**hypers)\n",
    "kernel = Kernel(soap, name='GAP', zeta=zeta, target_type='Structure', kernel_type='Sparse') #Define Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e6ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute kernel\n",
    "start=time()\n",
    "Knm_FPS = compute_KNM(tqdm(train_set_FPS[:ntrain], desc=\"Compute KNM\", leave=False), X_sparse_FPS, kernel, soap)\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cc29ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save kernel\n",
    "np.save('raw_data/Knm_kernel_hypers_6_4', Knm_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9715e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Knm_FPS = np.load('raw_data/Knm_kernel_hypers_6_4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train GAP model\n",
    "print(\"Training GAP model...\")\n",
    "start = time()\n",
    "full_model = train_gap_model(kernel, train_set_FPS[:ntrain], Knm_FPS, X_sparse_FPS, ytrain_FPS[:ntrain], y_dressed, \n",
    "                        grad_train=-get_forces(train_set_FPS[:ntrain]), lambdas=[0.055,3.25], jitter=1e-9, \n",
    "                        solver = 'RKHS')\n",
    "print(\"Time taken:\", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfcb839",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#predict energies and forces for validation set\n",
    "npred=1000\n",
    "yvp = []\n",
    "fvp = []\n",
    "\n",
    "for ifrm, frm in enumerate(tqdm(val_set[:npred], desc = \"Making predictions for validation set...\", leave=False)):\n",
    "    manager_val = soap.transform(frm)\n",
    "    yvp.append(full_model.predict(manager_val))\n",
    "    fvp.append(full_model.predict_forces(manager_val))\n",
    "\n",
    "yval_pred = np.array(yvp).flatten()\n",
    "fval_pred = np.concatenate(fvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba161d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predicted vs. actual energies and forces\n",
    "f,p = plt.subplots(1,2, figsize = (10, 5))\n",
    "p[0].scatter((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1),\n",
    "             (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))\n",
    "p[0].set_title('Energies (eV)')\n",
    "p[0].set()\n",
    "p[1].scatter(fval_true.flatten()[:npred], fval_pred.flatten()[:npred])\n",
    "p[1].set_title(r'Forces (ev/$\\AA$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9974e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_energy = np.sqrt(np.mean(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d4c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_forces = np.sqrt(np.mean((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff30512",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_energy, rmse_forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ccbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('results_data/hyper64_results.txt', np.array([rmse_energy, rmse_forces]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f155b",
   "metadata": {},
   "source": [
    "## Effect of reducing SOAP angular cutoff on predicion accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 8400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b421ceee",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Define hyperparameters and SOAP\n",
    "hypers[\"compute_gradients\"] = False\n",
    "hypers[\"interaction_cutoff\"] = 4\n",
    "hypers[\"max_radial\"] = 9\n",
    "hypers[\"max_angular\"] = 6\n",
    "soap = SphericalInvariants(**hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b83c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute feature matrices\n",
    "print(\"Computing feature matrices...\")\n",
    "start=time()\n",
    "manager_train = soap.transform(train_set_FPS[:ntrain]) #calculating features\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7f4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an FPS filter to obtain desired number of sparse points per species\n",
    "nh = 1778\n",
    "nc = 1467\n",
    "nn = 1467\n",
    "no = 1778\n",
    "nsparse    = {1: nh, 6: nc, 7: nn, 8: no} #Select number of sparse environemnts per species\n",
    "compressor = FPSFilter(soap,nsparse,act_on='sample per species') #Filter to sparsify full feature matrix\n",
    "print(\"Sparsifying training set...\")\n",
    "start=time()\n",
    "X_sparse_FPS = compressor.select_and_filter(manager_train) #Apply filter to training set\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976df96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_obj('raw_data/X_sparse_rc_4.json', X_sparse_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa6ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sparse_FPS = load_obj('raw_data/X_sparse_rc_4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define kernel and redefine hypers \n",
    "hypers[\"compute_gradients\"] = True #we want to compute gradients (forces) for the kernel\n",
    "soap = SphericalInvariants(**hypers)\n",
    "kernel = Kernel(soap, name='GAP', zeta=zeta, target_type='Structure', kernel_type='Sparse') #Define Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute kernel\n",
    "start=time()\n",
    "Knm_FPS = compute_KNM(tqdm(train_set_FPS[:ntrain], desc=\"Compute KNM\", leave=False), X_sparse_FPS, kernel, soap)\n",
    "print(\"Time taken: \", time()-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a6db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save kernel\n",
    "np.save('raw_data/Knm_kernel_rc_4', Knm_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0f7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Knm_FPS = np.load('raw_data/Knm_kernel_rc_4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb00391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train GAP model\n",
    "print(\"Training GAP model...\")\n",
    "start = time()\n",
    "full_model = train_gap_model(kernel, train_set_FPS[:ntrain], Knm_FPS, X_sparse_FPS, ytrain_FPS[:ntrain], y_dressed, \n",
    "                        grad_train=-get_forces(train_set_FPS[:ntrain]), lambdas=[0.055,3.25], jitter=1e-9, \n",
    "                        solver = 'RKHS')\n",
    "print(\"Time taken:\", time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6433237",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#predict energies and forces for validation set\n",
    "npred=1000\n",
    "yvp = []\n",
    "fvp = []\n",
    "\n",
    "for ifrm, frm in enumerate(tqdm(val_set[:npred], desc = \"Making predictions for validation set...\", leave=False)):\n",
    "    manager_val = soap.transform(frm)\n",
    "    yvp.append(full_model.predict(manager_val))\n",
    "    fvp.append(full_model.predict_forces(manager_val))\n",
    "\n",
    "yval_pred = np.array(yvp).flatten()\n",
    "fval_pred = np.concatenate(fvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot predicted vs. actual energies and forces\n",
    "f,p = plt.subplots(1,2, figsize = (10, 5))\n",
    "p[0].scatter((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1),\n",
    "             (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))\n",
    "p[0].set_title('Energies (eV)')\n",
    "p[0].set()\n",
    "p[1].scatter(fval_true.flatten()[:npred], fval_pred.flatten()[:npred])\n",
    "p[1].set_title(r'Forces (ev/$\\AA$)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50de90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_energy = np.sqrt(np.mean(((yval_true[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1) - (yval_pred[:npred] - mlr.predict(X_val[:npred]))/np.sum(X_val[:npred],axis=1))**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_forces = np.sqrt(np.mean((fval_true.flatten()[:npred] - fval_pred.flatten()[:npred])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735ac73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_energy, rmse_forces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('rc_4_results.txt', np.array([rmse_energy, rmse_forces]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": "4",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
